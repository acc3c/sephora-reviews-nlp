{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cnfg\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn.preprocessing import Normalizer, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "import nltk\n",
    "\n",
    "import logging\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_url</th>\n",
       "      <th>sku</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>detail_text</th>\n",
       "      <th>size_oz</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P102503</th>\n",
       "      <td>/wrinkle-revenge-rescue-protect-facial-cream-P...</td>\n",
       "      <td>844480</td>\n",
       "      <td>moisturizers</td>\n",
       "      <td>DERMAdoctor</td>\n",
       "      <td>Wrinkle Revenge Rescue &amp; Protect Facial Cream</td>\n",
       "      <td>4.2366</td>\n",
       "      <td>What it is:A lightweight concentrate that deli...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P102504</th>\n",
       "      <td>/wrinkle-revenge-eye-balm-P102504</td>\n",
       "      <td>844472</td>\n",
       "      <td>eye creams &amp; treatments</td>\n",
       "      <td>DERMAdoctor</td>\n",
       "      <td>Wrinkle Revenge Eye Balm</td>\n",
       "      <td>4.0591</td>\n",
       "      <td>What it is:A super-hydrating eye balm enriched...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P107306</th>\n",
       "      <td>/renewing-eye-cream-P107306</td>\n",
       "      <td>769836</td>\n",
       "      <td>eye creams &amp; treatments</td>\n",
       "      <td>Murad</td>\n",
       "      <td>Renewing Eye Cream</td>\n",
       "      <td>4.0706</td>\n",
       "      <td>What it is: A multiactive, antiaging treatment...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               product_url     sku  \\\n",
       "id                                                                   \n",
       "P102503  /wrinkle-revenge-rescue-protect-facial-cream-P...  844480   \n",
       "P102504                  /wrinkle-revenge-eye-balm-P102504  844472   \n",
       "P107306                        /renewing-eye-cream-P107306  769836   \n",
       "\n",
       "                        category        brand  \\\n",
       "id                                              \n",
       "P102503             moisturizers  DERMAdoctor   \n",
       "P102504  eye creams & treatments  DERMAdoctor   \n",
       "P107306  eye creams & treatments        Murad   \n",
       "\n",
       "                                                  name  rating  \\\n",
       "id                                                               \n",
       "P102503  Wrinkle Revenge Rescue & Protect Facial Cream  4.2366   \n",
       "P102504                       Wrinkle Revenge Eye Balm  4.0591   \n",
       "P107306                             Renewing Eye Cream  4.0706   \n",
       "\n",
       "                                               detail_text  size_oz  price  \n",
       "id                                                                          \n",
       "P102503  What it is:A lightweight concentrate that deli...      1.7     57  \n",
       "P102504  What it is:A super-hydrating eye balm enriched...      0.5     50  \n",
       "P107306  What it is: A multiactive, antiaging treatment...      0.5     80  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = cnfg.load(\".metis_config\")\n",
    "engine = create_engine('postgresql://{}:{}@{}:5432/{}'.format(\n",
    "                        config['db_user'],\n",
    "                        config['db_pwd'],\n",
    "                        config['db_host'],\n",
    "                        'sephora'))\n",
    "\n",
    "query_product = \"\"\"SELECT * FROM sephora_product WHERE category IN ('moisturizers', 'face serums', 'face wash & cleansers',\n",
    "         'eye creams & treatments', 'face masks', 'moisturizer & treatments',\n",
    "         'face oils')\"\"\"\n",
    "df_product = pd.read_sql_query(query_product, engine)\n",
    "# df_product = pd.read_csv('data/sephora_product.csv')\n",
    "df_product = df_product.set_index('id')\n",
    "df_product.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>age_range</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>reviewer_username</th>\n",
       "      <th>tags</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P411015</td>\n",
       "      <td></td>\n",
       "      <td>I don't wear makeup but I love the highlighted...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lexium</td>\n",
       "      <td>None</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P411015</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P411015</td>\n",
       "      <td></td>\n",
       "      <td>Love this product! It's a wonderful way to giv...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MsZabeth</td>\n",
       "      <td>None</td>\n",
       "      <td>4a9ea1fa-3638-4bee-83db-85150f6db2e2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P411015</td>\n",
       "      <td>Very Dissapointed</td>\n",
       "      <td>If I could give this no stars, I would.</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dbaeznyc923</td>\n",
       "      <td>None</td>\n",
       "      <td>41814923-6e1f-4083-95a1-1bc0643c803d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P411015</td>\n",
       "      <td></td>\n",
       "      <td>It leaves a white cast like a sunscreen would....</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>selinakyle88</td>\n",
       "      <td>None</td>\n",
       "      <td>13236fb4-242b-44a8-8fc0-e6896d3aed24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id             review_title  \\\n",
       "0    P411015                            \n",
       "1    P411015  Much too shiny/shimmery   \n",
       "2    P411015                            \n",
       "3    P411015        Very Dissapointed   \n",
       "4    P411015                            \n",
       "\n",
       "                                         review_text  rating age_range  \\\n",
       "0  I don't wear makeup but I love the highlighted...       5      None   \n",
       "1  This glotion is much to shimmery and when used...       2      None   \n",
       "2  Love this product! It's a wonderful way to giv...       5      None   \n",
       "3           If I could give this no stars, I would.        1      None   \n",
       "4  It leaves a white cast like a sunscreen would....       3      None   \n",
       "\n",
       "  skin_type skin_tone eye_color reviewer_username  tags  \\\n",
       "0      None      None      None            Lexium  None   \n",
       "1       dry      None      None          dsmartin  None   \n",
       "2      None      None      None          MsZabeth  None   \n",
       "3    normal      None      None       dbaeznyc923  None   \n",
       "4      None      None      None      selinakyle88  None   \n",
       "\n",
       "                              review_id  \n",
       "0  8f7a235d-71ec-4d55-a7fb-5275964dc47f  \n",
       "1  f9e384e1-2182-49e8-9e8b-c3df0f22d263  \n",
       "2  4a9ea1fa-3638-4bee-83db-85150f6db2e2  \n",
       "3  41814923-6e1f-4083-95a1-1bc0643c803d  \n",
       "4  13236fb4-242b-44a8-8fc0-e6896d3aed24  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_review = 'SELECT * FROM sephora_product_review'\n",
    "df = pd.read_sql_query(query_review, engine)\n",
    "# df = pd.read_csv('data/sephora_review.csv')\n",
    "# df = df[df.rating <= 3]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Smith is a doctor.', 'He is the best ... not']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.set_index('review_id')\n",
    "\n",
    "# Split review_text into sentences\n",
    "punkt_param = PunktParameters()\n",
    "punkt_param.abbrev_types = set(['dr', 'vs', 'mr', 'mrs'])\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "tokenizer.tokenize('Dr. Smith is a doctor. He is the best ... not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['review_sentences'] = df['review_text'].map(lambda text: tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I could give this no stars, I would. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['If I could give this no stars, I would.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review_index = 3\n",
    "print(df.iloc[sample_review_index]['review_text'])\n",
    "df.iloc[sample_review_index]['review_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at first it took a few times to figure out the best way to wrap the magnet',\n",
       " \"if you don't it's almost impossible to get the product off\",\n",
       " 'then this is great',\n",
       " 'it absorbs fairly quick',\n",
       " '3-5 minutes depending on how much serum you use',\n",
       " \"it's too oily to use as an eye-makeup remover\",\n",
       " 'the scent is over powering',\n",
       " 'the dispenser does not work well',\n",
       " \"it'll leave this oily film over your eye balls\",\n",
       " 'cloud your vision until your eye does its job',\n",
       " 'coughs the film back out in the form of an eye booger',\n",
       " 'almost can feel like it is burning sometimes',\n",
       " 'have to use this on nights i am not doing anything other than washing my face']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_long_sentence(sentences):\n",
    "    shorter_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) >= 50:\n",
    "            sub_sentences = re.split('&|!|;|and|,|~|but|\\.|so i|\\s-\\s|\\(|\\)', sentence.lower())\n",
    "            sub_sentences = [s.strip() for s in sub_sentences]\n",
    "            shorter_sentences += sub_sentences\n",
    "        else:\n",
    "            shorter_sentences.append(sentence.lower())\n",
    "    shorter_sentences = filter(lambda s: len(s) > 13 \n",
    "                               and not s.startswith('i have')\n",
    "                               and not s.startswith('i also have')\n",
    "                               and not s.startswith('i\\'m')\n",
    "                               and not s.startswith('i had')\n",
    "                               and not s.startswith('i\\'ve been')\n",
    "                               and not s.startswith('i thought')\n",
    "                               and not s.startswith('i was ')\n",
    "                               and not s.startswith('i use ')\n",
    "                               and not s.startswith('i used to')\n",
    "                               and not s.startswith('if you have')\n",
    "                               and not ('i do have' in s)\n",
    "                               and not ('looking for' in s)\n",
    "                               and not ('i purchase' in s)\n",
    "                               and not ('i bought' in s)\n",
    "                               , shorter_sentences)\n",
    "    return list(shorter_sentences)\n",
    "\n",
    "split_long_sentence([\n",
    "    \"I have mild acne\",\n",
    "    \"i do have to comment on the packaging because it is as terrible as everyone says it is\"\n",
    "    \"Totally I was on the lookout for a long time fora great moisturizer\",\n",
    "    \"At first it took a few times to figure out the best way to wrap the magnet (if you don't it's almost impossible to get the product off) then this is great\",\n",
    "    \"It absorbs fairly quick - 3-5 minutes depending on how much serum you use.\",\n",
    "    \"It's too oily to use as an eye-makeup remover and the scent is over powering, the dispenser does not work well\", \n",
    "    \"It'll leave this oily film over your eye balls and cloud your vision until your eye does its job but coughs the film back out in the form of an eye booger...so maybe not\",\n",
    "    \"almost can feel like it is burning sometimes so I have to use this on nights I am not doing anything other than washing my face.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>i don't wear makeup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>i love the highlighted look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>this is perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>it doesn't feel cakey or break me out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>i don't think it's too glittery or bright.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id  \\\n",
       "0  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "1  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "2  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "3  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "4  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "\n",
       "                                     sentence  \n",
       "0                         i don't wear makeup  \n",
       "1                 i love the highlighted look  \n",
       "2                             this is perfect  \n",
       "3       it doesn't feel cakey or break me out  \n",
       "4  i don't think it's too glittery or bright.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a new dataframe with each sentence as a document\n",
    "review_ids = []\n",
    "review_sentences = []\n",
    "for review in df.as_matrix():\n",
    "    curr_review_id = review[-2]\n",
    "    curr_review_sentences = review[-1]\n",
    "    \n",
    "    # Divide long sentences even longer if possible!\n",
    "    shorter_sentences = split_long_sentence(curr_review_sentences)\n",
    "    \n",
    "    review_ids += [curr_review_id] * len(shorter_sentences)\n",
    "    review_sentences += shorter_sentences\n",
    "    \n",
    "df_review_sentences = pd.DataFrame({'review_id': review_ids, 'sentence': review_sentences})\n",
    "df_review_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744640, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get stop words\n",
    "stop_words = set(open('data/stopwords_v2.txt').read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer_regex = re.compile(r\"[\\s]\")\n",
    "\n",
    "def tokenize(text):\n",
    "    clean_text = re.sub(r'[,!.$\\d%&~?()#<>\"=/-]', ' ', text)\n",
    "    clean_text = ' '.join(clean_text.split())\n",
    "    tokens = [tok.strip().lower() for tok in tokenizer_regex.split(clean_text)]\n",
    "    filtered_tokens = filter(lambda tok: tok not in stop_words, tokens)\n",
    "    return list(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'def']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('skin abc & def<')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.get_word_weights.<locals>.<lambda>>,\n",
       "            {'bird': 1.8472978603872037,\n",
       "             'blah': 2.2527629684953681,\n",
       "             'cat': 1.5596157879354227,\n",
       "             'dog': 1.8472978603872037,\n",
       "             'fish': 1.5596157879354227})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_weights(docs):\n",
    "    tfidf = TfidfVectorizer(stop_words=frozenset(), \n",
    "                            tokenizer=tokenize,\n",
    "                            ngram_range=(1,1))\n",
    "    tfidf.fit(docs)\n",
    "    max_idf = max(tfidf.idf_)\n",
    "    word2weight = defaultdict(lambda: max_idf,\n",
    "                                    [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    return word2weight\n",
    "    \n",
    "test_docs2 = [\"dog cat fish\",\"dog cat cat\",\"fish bird\", 'bird fish. bird', 'blah cat', 'tata harper']\n",
    "get_word_weights(test_docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-24 10:31:33,732 : INFO : loading projection weights from ../GoogleNews-vectors-negative300.bin\n",
      "2017-08-24 10:32:42,028 : INFO : loaded (3000000, 300) matrix from ../GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "w2v = models.KeyedVectors.load_word2vec_format(\"../GoogleNews-vectors-negative300.bin\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.mean(w2v[['it\\'s', 'is', 'moisturizer', 'reviews']], axis=0)\n",
    "# w2v['wrinkle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-24 10:32:42,038 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('wrinkles', 0.6509594917297363),\n",
       " ('twist', 0.5201830863952637),\n",
       " ('cellulite', 0.4519196152687073),\n",
       " ('wrinkle_remover', 0.4473875164985657),\n",
       " ('kink', 0.43007057905197144),\n",
       " ('creases', 0.4271658658981323),\n",
       " ('Botox', 0.42587846517562866),\n",
       " ('wrinkle_reducer', 0.42533019185066223),\n",
       " (\"crow's_feet\", 0.42372927069664),\n",
       " ('wrinkle_filler', 0.42249032855033875),\n",
       " ('Prevage', 0.4219375550746918),\n",
       " ('dimension', 0.41997307538986206),\n",
       " ('volumizing', 0.41956183314323425),\n",
       " ('Frownies', 0.4190055727958679),\n",
       " ('slenderizing', 0.41443490982055664),\n",
       " ('eye_makeup_remover', 0.41385316848754883),\n",
       " ('stimulates_collagen_production', 0.41349709033966064),\n",
       " ('aging_creams', 0.41251763701438904),\n",
       " ('cellulite_creams', 0.41042596101760864),\n",
       " ('exfoliant', 0.40742120146751404),\n",
       " ('facial_creases', 0.4038386642932892),\n",
       " ('aging_serums', 0.40091755986213684),\n",
       " ('Sculptra', 0.40089690685272217),\n",
       " ('translucent_powder', 0.40067803859710693),\n",
       " ('self_tanner', 0.4004167914390564)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['wrinkle'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'review' in w2v.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_review_sentences['tokenized_words'] = df_review_sentences['sentence'].map(lambda sentence: tokenize(sentence))\n",
    "df_review_sentences['tokenized_filtered_words'] = df_review_sentences['tokenized_words'].map(\n",
    "    lambda tokenized_words: [word for word in tokenized_words if word in w2v.vocab])\n",
    "df_review_sentences['tokenized_filtered_words_length'] = df_review_sentences['tokenized_filtered_words'].map(\n",
    "    lambda tokenized_filtered_words: len(tokenized_filtered_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sentences that less than 4 words\n",
    "df_review_sentences = df_review_sentences[df_review_sentences.tokenized_filtered_words_length > 3]\n",
    "df_review_sentences = df_review_sentences.reset_index()\n",
    "word2weight = get_word_weights(df_review_sentences['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use parts of speech\n",
    "def get_pos_weight(tokens):\n",
    "    word_pos = nltk.pos_tag(tokens)\n",
    "    word_to_weight = {}\n",
    "    for word, pos in word_pos:\n",
    "        if pos.startswith('JJ'):\n",
    "            # adjective\n",
    "            word_to_weight[word] = 4\n",
    "        elif pos.startswith('RB'):\n",
    "            # adverb\n",
    "            word_to_weight[word] = 3\n",
    "        elif pos.startswith('VB'):\n",
    "            # verb\n",
    "            word_to_weight[word] = 2\n",
    "        else: \n",
    "            word_to_weight[word] = 1\n",
    "    return word_to_weight\n",
    "    \n",
    "    \n",
    "# nltk.pos_tag(['month', 'three', 'major', 'quickly', 'definitely'])\n",
    "#'vba'.startswith('vb')\n",
    "\n",
    "\n",
    "def word2vec_pos_weight(tokenized_filtered_words):\n",
    "    pos_weights = get_pos_weight(tokenized_filtered_words)\n",
    "    return np.mean([w2v[w] * pos_weights[w]\n",
    "             for w in tokenized_filtered_words], axis=0)\n",
    "\n",
    "# word2vec_pos_weight(['month', 'three', 'major', 'quickly', 'definitely'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each sentence, find word2vec vector\n",
    "# np.mean(w2v[['it\\'s', 'is', 'moisturizer', 'reviews']], axis=0)\n",
    "def word2vec_tfidf(tokenized_filtered_words):\n",
    "    return np.mean([w2v[w] * word2weight[w]\n",
    "             for w in tokenized_filtered_words], axis=0)\n",
    "\n",
    "word2vec_tfidf(['apple', 'banana']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized_filtered_words</th>\n",
       "      <th>tokenized_filtered_words_length</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>it doesn't feel cakey or break me out</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0308431, 0.00958252, -0.0441488, 0.144043, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>i don't think it's too glittery or bright.</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.147441, -0.0728353, 0.115743, 0.39681, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>the best part is that it shows up on my light ...</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0922546, 0.0911621, 0.204285, 0.146484, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>when used all over the face</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.164062, 0.079895, 0.169098, 0.104126, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>does not look at all natural</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0712077, 0.149882, 0.0592448, 0.266846, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             review_id  \\\n",
       "0      3  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "1      4  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "2      6  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "3      8  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "4     10  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "\n",
       "                                            sentence  \\\n",
       "0              it doesn't feel cakey or break me out   \n",
       "1         i don't think it's too glittery or bright.   \n",
       "2  the best part is that it shows up on my light ...   \n",
       "3                        when used all over the face   \n",
       "4                       does not look at all natural   \n",
       "\n",
       "                              tokenized_words  \\\n",
       "0       [doesn't, feel, cakey, or, break, me]   \n",
       "1  [don't, think, it's, glittery, or, bright]   \n",
       "2            [best, part, that, shows, light]   \n",
       "3                     [when, used, all, over]   \n",
       "4         [does, not, look, at, all, natural]   \n",
       "\n",
       "                     tokenized_filtered_words  \\\n",
       "0       [doesn't, feel, cakey, or, break, me]   \n",
       "1  [don't, think, it's, glittery, or, bright]   \n",
       "2            [best, part, that, shows, light]   \n",
       "3                     [when, used, all, over]   \n",
       "4         [does, not, look, at, all, natural]   \n",
       "\n",
       "   tokenized_filtered_words_length  \\\n",
       "0                                6   \n",
       "1                                6   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                6   \n",
       "\n",
       "                                            word2vec  \n",
       "0  [0.0308431, 0.00958252, -0.0441488, 0.144043, ...  \n",
       "1  [0.147441, -0.0728353, 0.115743, 0.39681, -0.2...  \n",
       "2  [-0.0922546, 0.0911621, 0.204285, 0.146484, 0....  \n",
       "3  [0.164062, 0.079895, 0.169098, 0.104126, -0.10...  \n",
       "4  [0.0712077, 0.149882, 0.0592448, 0.266846, -0....  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_sentences['word2vec'] = df_review_sentences['tokenized_filtered_words'].map(\n",
    "    # lambda tokenized_filtered_words: np.mean(w2v[tokenized_filtered_words], axis=0)\n",
    "    # lambda tokenized_filtered_words: word2vec_tfidf(tokenized_filtered_words)\n",
    "    lambda tokenized_filtered_words: word2vec_pos_weight(tokenized_filtered_words)\n",
    ")\n",
    "df_review_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(df_review_sentences['word2vec'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_word_vectors = np.array(df_review_sentences['word2vec'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_kmeans_inertia(data):\n",
    "    \"\"\"Figure out optimized number of clusters for KMeans\"\"\"\n",
    "    max_number_clusters = 20\n",
    "    inertia_values = []\n",
    "    for cluster_count in range(1, max_number_clusters+1):\n",
    "        print('fitting cluster ', cluster_count)\n",
    "        km = KMeans(n_clusters=cluster_count)\n",
    "        km.fit(data)\n",
    "        inertia_values.append(km.inertia_)\n",
    "\n",
    "    plt.plot(range(1, max_number_clusters+1), inertia_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401946, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401946, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_count = 30\n",
    "number_sentences = sentence_word_vectors.shape[0]\n",
    "df_review_sentences_truncated = df_review_sentences.iloc[0:number_sentences, :]\n",
    "sentence_word_vectors_truncated = sentence_word_vectors[0:number_sentences, :]\n",
    "sentence_word_vectors_truncated = normalize(sentence_word_vectors_truncated)\n",
    "sentence_word_vectors_truncated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401946"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = MiniBatchKMeans(n_clusters=cluster_count)\n",
    "review_word2vec_clusters = km.fit_predict(sentence_word_vectors_truncated)\n",
    "len(review_word2vec_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized_filtered_words</th>\n",
       "      <th>tokenized_filtered_words_length</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>34</td>\n",
       "      <td>35be24c1-28f7-415a-8bc7-734c21c0ab94</td>\n",
       "      <td>when i used it for the first time i was so exc...</td>\n",
       "      <td>[when, used, was, excited]</td>\n",
       "      <td>[when, used, was, excited]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0571899, 0.256348, 0.382812, -0.0513306, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>278</td>\n",
       "      <td>c3bcfbce-c45f-496e-9530-1a8e6123bef4</td>\n",
       "      <td>the cleanser does a better job at removing mas...</td>\n",
       "      <td>[does, better, job, at, removing, than]</td>\n",
       "      <td>[does, better, job, at, removing, than]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-0.130117, 0.0537109, -0.00696564, 0.164286, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>283</td>\n",
       "      <td>8255954b-ebf4-4853-b3ab-4591d2629af2</td>\n",
       "      <td>i wanted something that would foam up better w...</td>\n",
       "      <td>[wanted, something, that, would, foam, better,...</td>\n",
       "      <td>[wanted, something, that, would, foam, better,...</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.111067, 0.0373535, 0.112549, 0.124442, -0....</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>399</td>\n",
       "      <td>4955ed99-9be5-457c-8414-ce48a3838b08</td>\n",
       "      <td>my crows feet have gotten better</td>\n",
       "      <td>[crows, feet, have, gotten, better]</td>\n",
       "      <td>[crows, feet, have, gotten, better]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.202441, 0.0154297, -0.205835, 0.201498, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>404</td>\n",
       "      <td>4955ed99-9be5-457c-8414-ce48a3838b08</td>\n",
       "      <td>i wish it were a bit cheaper because the tube ...</td>\n",
       "      <td>[wish, were, bit, cheaper, because, tube, small]</td>\n",
       "      <td>[wish, were, bit, cheaper, because, tube, small]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.057251, 0.0616281, -0.0561349, 0.418178, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                             review_id  \\\n",
       "18      34  35be24c1-28f7-415a-8bc7-734c21c0ab94   \n",
       "161    278  c3bcfbce-c45f-496e-9530-1a8e6123bef4   \n",
       "164    283  8255954b-ebf4-4853-b3ab-4591d2629af2   \n",
       "216    399  4955ed99-9be5-457c-8414-ce48a3838b08   \n",
       "220    404  4955ed99-9be5-457c-8414-ce48a3838b08   \n",
       "\n",
       "                                              sentence  \\\n",
       "18   when i used it for the first time i was so exc...   \n",
       "161  the cleanser does a better job at removing mas...   \n",
       "164  i wanted something that would foam up better w...   \n",
       "216                   my crows feet have gotten better   \n",
       "220  i wish it were a bit cheaper because the tube ...   \n",
       "\n",
       "                                       tokenized_words  \\\n",
       "18                          [when, used, was, excited]   \n",
       "161            [does, better, job, at, removing, than]   \n",
       "164  [wanted, something, that, would, foam, better,...   \n",
       "216                [crows, feet, have, gotten, better]   \n",
       "220   [wish, were, bit, cheaper, because, tube, small]   \n",
       "\n",
       "                              tokenized_filtered_words  \\\n",
       "18                          [when, used, was, excited]   \n",
       "161            [does, better, job, at, removing, than]   \n",
       "164  [wanted, something, that, would, foam, better,...   \n",
       "216                [crows, feet, have, gotten, better]   \n",
       "220   [wish, were, bit, cheaper, because, tube, small]   \n",
       "\n",
       "     tokenized_filtered_words_length  \\\n",
       "18                                 4   \n",
       "161                                6   \n",
       "164                                7   \n",
       "216                                5   \n",
       "220                                7   \n",
       "\n",
       "                                              word2vec  feat_0  feat_1  \\\n",
       "18   [0.0571899, 0.256348, 0.382812, -0.0513306, 0....       1       0   \n",
       "161  [-0.130117, 0.0537109, -0.00696564, 0.164286, ...       1       0   \n",
       "164  [-0.111067, 0.0373535, 0.112549, 0.124442, -0....       1       0   \n",
       "216  [-0.202441, 0.0154297, -0.205835, 0.201498, -0...       1       0   \n",
       "220  [-0.057251, 0.0616281, -0.0561349, 0.418178, -...       1       0   \n",
       "\n",
       "     feat_2   ...     feat_20  feat_21  feat_22  feat_23  feat_24  feat_25  \\\n",
       "18        0   ...           0        0        0        0        0        0   \n",
       "161       0   ...           0        0        0        0        0        0   \n",
       "164       0   ...           0        0        0        0        0        0   \n",
       "216       0   ...           0        0        0        0        0        0   \n",
       "220       0   ...           0        0        0        0        0        0   \n",
       "\n",
       "     feat_26  feat_27  feat_28  feat_29  \n",
       "18         0        0        0        0  \n",
       "161        0        0        0        0  \n",
       "164        0        0        0        0  \n",
       "216        0        0        0        0  \n",
       "220        0        0        0        0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vector of sentence to cluster number\n",
    "df_sentence_cluster = pd.DataFrame({})\n",
    "cluster_columns = ['feat_' + str(i) for i in range(0, cluster_count)]\n",
    "for i in range(0, cluster_count):\n",
    "    cluster_column = cluster_columns[i]\n",
    "    df_sentence_cluster[cluster_column] = (review_word2vec_clusters == i).astype(int)\n",
    "    \n",
    "df_sentence = pd.concat([df_review_sentences, df_sentence_cluster], axis=1)\n",
    "df_sentence[df_sentence['feat_0'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Review Sentences with Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized_filtered_words</th>\n",
       "      <th>tokenized_filtered_words_length</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>age_range</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>reviewer_username</th>\n",
       "      <th>tags</th>\n",
       "      <th>review_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>it doesn't feel cakey or break me out</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0308431, 0.00958252, -0.0441488, 0.144043, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>I don't wear makeup but I love the highlighted...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lexium</td>\n",
       "      <td>None</td>\n",
       "      <td>[I don't wear makeup but I love the highlighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>i don't think it's too glittery or bright.</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.147441, -0.0728353, 0.115743, 0.39681, -0.2...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>I don't wear makeup but I love the highlighted...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lexium</td>\n",
       "      <td>None</td>\n",
       "      <td>[I don't wear makeup but I love the highlighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8f7a235d-71ec-4d55-a7fb-5275964dc47f</td>\n",
       "      <td>the best part is that it shows up on my light ...</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0922546, 0.0911621, 0.204285, 0.146484, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>I don't wear makeup but I love the highlighted...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Lexium</td>\n",
       "      <td>None</td>\n",
       "      <td>[I don't wear makeup but I love the highlighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>when used all over the face</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.164062, 0.079895, 0.169098, 0.104126, -0.10...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>[This glotion is much to shimmery and when use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>does not look at all natural</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0712077, 0.149882, 0.0592448, 0.266846, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>[This glotion is much to shimmery and when use...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             review_id  \\\n",
       "0      3  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "1      4  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "2      6  8f7a235d-71ec-4d55-a7fb-5275964dc47f   \n",
       "3      8  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "4     10  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "\n",
       "                                            sentence  \\\n",
       "0              it doesn't feel cakey or break me out   \n",
       "1         i don't think it's too glittery or bright.   \n",
       "2  the best part is that it shows up on my light ...   \n",
       "3                        when used all over the face   \n",
       "4                       does not look at all natural   \n",
       "\n",
       "                              tokenized_words  \\\n",
       "0       [doesn't, feel, cakey, or, break, me]   \n",
       "1  [don't, think, it's, glittery, or, bright]   \n",
       "2            [best, part, that, shows, light]   \n",
       "3                     [when, used, all, over]   \n",
       "4         [does, not, look, at, all, natural]   \n",
       "\n",
       "                     tokenized_filtered_words  \\\n",
       "0       [doesn't, feel, cakey, or, break, me]   \n",
       "1  [don't, think, it's, glittery, or, bright]   \n",
       "2            [best, part, that, shows, light]   \n",
       "3                     [when, used, all, over]   \n",
       "4         [does, not, look, at, all, natural]   \n",
       "\n",
       "   tokenized_filtered_words_length  \\\n",
       "0                                6   \n",
       "1                                6   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                6   \n",
       "\n",
       "                                            word2vec  feat_0  feat_1  feat_2  \\\n",
       "0  [0.0308431, 0.00958252, -0.0441488, 0.144043, ...       0       0       0   \n",
       "1  [0.147441, -0.0728353, 0.115743, 0.39681, -0.2...       0       1       0   \n",
       "2  [-0.0922546, 0.0911621, 0.204285, 0.146484, 0....       0       0       0   \n",
       "3  [0.164062, 0.079895, 0.169098, 0.104126, -0.10...       0       0       0   \n",
       "4  [0.0712077, 0.149882, 0.0592448, 0.266846, -0....       0       0       0   \n",
       "\n",
       "                         ...                                     review_title  \\\n",
       "0                        ...                                                    \n",
       "1                        ...                                                    \n",
       "2                        ...                                                    \n",
       "3                        ...                          Much too shiny/shimmery   \n",
       "4                        ...                          Much too shiny/shimmery   \n",
       "\n",
       "                                         review_text  rating  age_range  \\\n",
       "0  I don't wear makeup but I love the highlighted...       5       None   \n",
       "1  I don't wear makeup but I love the highlighted...       5       None   \n",
       "2  I don't wear makeup but I love the highlighted...       5       None   \n",
       "3  This glotion is much to shimmery and when used...       2       None   \n",
       "4  This glotion is much to shimmery and when used...       2       None   \n",
       "\n",
       "   skin_type  skin_tone  eye_color  reviewer_username  tags  \\\n",
       "0       None       None       None             Lexium  None   \n",
       "1       None       None       None             Lexium  None   \n",
       "2       None       None       None             Lexium  None   \n",
       "3        dry       None       None           dsmartin  None   \n",
       "4        dry       None       None           dsmartin  None   \n",
       "\n",
       "                                    review_sentences  \n",
       "0  [I don't wear makeup but I love the highlighte...  \n",
       "1  [I don't wear makeup but I love the highlighte...  \n",
       "2  [I don't wear makeup but I love the highlighte...  \n",
       "3  [This glotion is much to shimmery and when use...  \n",
       "4  [This glotion is much to shimmery and when use...  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence_product = pd.merge(df_sentence, df, on='review_id', how='left')\n",
    "df_sentence_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanawu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py:2844: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized_filtered_words</th>\n",
       "      <th>tokenized_filtered_words_length</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>neg_feat_0</th>\n",
       "      <th>neg_feat_1</th>\n",
       "      <th>neg_feat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>age_range</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>reviewer_username</th>\n",
       "      <th>tags</th>\n",
       "      <th>review_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>when used all over the face</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>[when, used, all, over]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.164062, 0.079895, 0.169098, 0.104126, -0.10...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>[This glotion is much to shimmery and when use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>does not look at all natural</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>[does, not, look, at, all, natural]</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0712077, 0.149882, 0.0592448, 0.266846, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>[This glotion is much to shimmery and when use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>f9e384e1-2182-49e8-9e8b-c3df0f22d263</td>\n",
       "      <td>it does ok in very small amounts as a spot hig...</td>\n",
       "      <td>[does, ok, very, small, amounts, as, spot, hig...</td>\n",
       "      <td>[does, ok, very, small, amounts, as, spot, hig...</td>\n",
       "      <td>8</td>\n",
       "      <td>[0.175991, 0.109528, -0.0448456, 0.208946, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Much too shiny/shimmery</td>\n",
       "      <td>This glotion is much to shimmery and when used...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>dry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dsmartin</td>\n",
       "      <td>None</td>\n",
       "      <td>[This glotion is much to shimmery and when use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23</td>\n",
       "      <td>41814923-6e1f-4083-95a1-1bc0643c803d</td>\n",
       "      <td>if i could give this no stars, i would.</td>\n",
       "      <td>[if, could, give, stars, would]</td>\n",
       "      <td>[if, could, give, stars, would]</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0856689, 0.000537109, 0.124902, 0.150684, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Very Dissapointed</td>\n",
       "      <td>If I could give this no stars, I would.</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>normal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dbaeznyc923</td>\n",
       "      <td>None</td>\n",
       "      <td>[If I could give this no stars, I would.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>13236fb4-242b-44a8-8fc0-e6896d3aed24</td>\n",
       "      <td>it leaves a white cast like a sunscreen would.</td>\n",
       "      <td>[leaves, white, cast, like, would]</td>\n",
       "      <td>[leaves, white, cast, like, would]</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.14707, 0.16582, 0.0545807, -0.0119385, 0.05...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>It leaves a white cast like a sunscreen would....</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>selinakyle88</td>\n",
       "      <td>None</td>\n",
       "      <td>[It leaves a white cast like a sunscreen would...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                             review_id  \\\n",
       "3       8  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "4      10  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "5      11  f9e384e1-2182-49e8-9e8b-c3df0f22d263   \n",
       "12     23  41814923-6e1f-4083-95a1-1bc0643c803d   \n",
       "13     24  13236fb4-242b-44a8-8fc0-e6896d3aed24   \n",
       "\n",
       "                                             sentence  \\\n",
       "3                         when used all over the face   \n",
       "4                        does not look at all natural   \n",
       "5   it does ok in very small amounts as a spot hig...   \n",
       "12            if i could give this no stars, i would.   \n",
       "13     it leaves a white cast like a sunscreen would.   \n",
       "\n",
       "                                      tokenized_words  \\\n",
       "3                             [when, used, all, over]   \n",
       "4                 [does, not, look, at, all, natural]   \n",
       "5   [does, ok, very, small, amounts, as, spot, hig...   \n",
       "12                    [if, could, give, stars, would]   \n",
       "13                 [leaves, white, cast, like, would]   \n",
       "\n",
       "                             tokenized_filtered_words  \\\n",
       "3                             [when, used, all, over]   \n",
       "4                 [does, not, look, at, all, natural]   \n",
       "5   [does, ok, very, small, amounts, as, spot, hig...   \n",
       "12                    [if, could, give, stars, would]   \n",
       "13                 [leaves, white, cast, like, would]   \n",
       "\n",
       "    tokenized_filtered_words_length  \\\n",
       "3                                 4   \n",
       "4                                 6   \n",
       "5                                 8   \n",
       "12                                5   \n",
       "13                                5   \n",
       "\n",
       "                                             word2vec  neg_feat_0  neg_feat_1  \\\n",
       "3   [0.164062, 0.079895, 0.169098, 0.104126, -0.10...           0           0   \n",
       "4   [0.0712077, 0.149882, 0.0592448, 0.266846, -0....           0           0   \n",
       "5   [0.175991, 0.109528, -0.0448456, 0.208946, -0....           0           0   \n",
       "12  [0.0856689, 0.000537109, 0.124902, 0.150684, -...           0           0   \n",
       "13  [0.14707, 0.16582, 0.0545807, -0.0119385, 0.05...           0           0   \n",
       "\n",
       "    neg_feat_2                        ...                          \\\n",
       "3            0                        ...                           \n",
       "4            0                        ...                           \n",
       "5            0                        ...                           \n",
       "12           0                        ...                           \n",
       "13           0                        ...                           \n",
       "\n",
       "               review_title  \\\n",
       "3   Much too shiny/shimmery   \n",
       "4   Much too shiny/shimmery   \n",
       "5   Much too shiny/shimmery   \n",
       "12        Very Dissapointed   \n",
       "13                            \n",
       "\n",
       "                                          review_text  rating  age_range  \\\n",
       "3   This glotion is much to shimmery and when used...       2       None   \n",
       "4   This glotion is much to shimmery and when used...       2       None   \n",
       "5   This glotion is much to shimmery and when used...       2       None   \n",
       "12           If I could give this no stars, I would.        1       None   \n",
       "13  It leaves a white cast like a sunscreen would....       3       None   \n",
       "\n",
       "    skin_type  skin_tone  eye_color  reviewer_username  tags  \\\n",
       "3         dry       None       None           dsmartin  None   \n",
       "4         dry       None       None           dsmartin  None   \n",
       "5         dry       None       None           dsmartin  None   \n",
       "12     normal       None       None        dbaeznyc923  None   \n",
       "13       None       None       None       selinakyle88  None   \n",
       "\n",
       "                                     review_sentences  \n",
       "3   [This glotion is much to shimmery and when use...  \n",
       "4   [This glotion is much to shimmery and when use...  \n",
       "5   [This glotion is much to shimmery and when use...  \n",
       "12          [If I could give this no stars, I would.]  \n",
       "13  [It leaves a white cast like a sunscreen would...  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataframe into two dataframes, one with positive sentences, another with negative sentences\n",
    "# Positive sentences:\n",
    "df_sentence_product_pos = df_sentence_product[df_sentence_product.rating > 3]\n",
    "df_sentence_product_neg = df_sentence_product[df_sentence_product.rating <= 3]\n",
    "\n",
    "# Rename features in df_sentence_product_neg\n",
    "neg_feature_columns = ['neg_' + col_name for col_name in cluster_columns]\n",
    "# df.rename(columns={'Leader': 'Commander'}, inplace=True)\n",
    "df_sentence_product_neg.rename(columns=dict(zip(cluster_columns, neg_feature_columns)), inplace=True)\n",
    "df_sentence_product_neg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack positive and negative dataframes on top of each other\n",
    "df_sentence_product_pos_neg = pd.concat([df_sentence_product_pos, df_sentence_product_neg])\n",
    "df_sentence_product_pos_neg = df_sentence_product_pos_neg.fillna(0)\n",
    "df_sentence_product_pos_neg = df_sentence_product_pos_neg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>age_range</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>...</th>\n",
       "      <th>review_title</th>\n",
       "      <th>reviewer_username</th>\n",
       "      <th>sentence</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>tags</th>\n",
       "      <th>tokenized_filtered_words</th>\n",
       "      <th>tokenized_filtered_words_length</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Lexium</td>\n",
       "      <td>it doesn't feel cakey or break me out</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>6</td>\n",
       "      <td>[doesn't, feel, cakey, or, break, me]</td>\n",
       "      <td>[0.0308431, 0.00958252, -0.0441488, 0.144043, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Lexium</td>\n",
       "      <td>i don't think it's too glittery or bright.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>6</td>\n",
       "      <td>[don't, think, it's, glittery, or, bright]</td>\n",
       "      <td>[0.147441, -0.0728353, 0.115743, 0.39681, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>Lexium</td>\n",
       "      <td>the best part is that it shows up on my light ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>5</td>\n",
       "      <td>[best, part, that, shows, light]</td>\n",
       "      <td>[-0.0922546, 0.0911621, 0.204285, 0.146484, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>MsZabeth</td>\n",
       "      <td>it's a wonderful way to give your face</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[it's, wonderful, give, your]</td>\n",
       "      <td>4</td>\n",
       "      <td>[it's, wonderful, give, your]</td>\n",
       "      <td>[0.218658, -0.125977, 0.060791, 0.606445, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>MsZabeth</td>\n",
       "      <td>all-over glow without adding color like a tint...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[all, over, glow, without, adding, color, like...</td>\n",
       "      <td>9</td>\n",
       "      <td>[all, over, glow, without, adding, color, like...</td>\n",
       "      <td>[0.0470208, 0.14072, 0.0886587, 0.0590617, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  age_range eye_color  feat_0  feat_1  feat_10  feat_11  feat_12  \\\n",
       "0        0          0         0     0.0     0.0      0.0      0.0      0.0   \n",
       "1        1          0         0     0.0     1.0      0.0      0.0      0.0   \n",
       "2        2          0         0     0.0     0.0      1.0      0.0      0.0   \n",
       "3        6          0         0     0.0     1.0      0.0      0.0      0.0   \n",
       "4        7          0         0     0.0     0.0      0.0      0.0      0.0   \n",
       "\n",
       "   feat_13  feat_14                        ...                          \\\n",
       "0      0.0      0.0                        ...                           \n",
       "1      0.0      0.0                        ...                           \n",
       "2      0.0      0.0                        ...                           \n",
       "3      0.0      0.0                        ...                           \n",
       "4      0.0      0.0                        ...                           \n",
       "\n",
       "   review_title  reviewer_username  \\\n",
       "0                           Lexium   \n",
       "1                           Lexium   \n",
       "2                           Lexium   \n",
       "3                         MsZabeth   \n",
       "4                         MsZabeth   \n",
       "\n",
       "                                            sentence  skin_tone  skin_type  \\\n",
       "0              it doesn't feel cakey or break me out          0          0   \n",
       "1         i don't think it's too glittery or bright.          0          0   \n",
       "2  the best part is that it shows up on my light ...          0          0   \n",
       "3             it's a wonderful way to give your face          0          0   \n",
       "4  all-over glow without adding color like a tint...          0          0   \n",
       "\n",
       "   tags                           tokenized_filtered_words  \\\n",
       "0     0              [doesn't, feel, cakey, or, break, me]   \n",
       "1     0         [don't, think, it's, glittery, or, bright]   \n",
       "2     0                   [best, part, that, shows, light]   \n",
       "3     0                      [it's, wonderful, give, your]   \n",
       "4     0  [all, over, glow, without, adding, color, like...   \n",
       "\n",
       "   tokenized_filtered_words_length  \\\n",
       "0                                6   \n",
       "1                                6   \n",
       "2                                5   \n",
       "3                                4   \n",
       "4                                9   \n",
       "\n",
       "                                     tokenized_words  \\\n",
       "0              [doesn't, feel, cakey, or, break, me]   \n",
       "1         [don't, think, it's, glittery, or, bright]   \n",
       "2                   [best, part, that, shows, light]   \n",
       "3                      [it's, wonderful, give, your]   \n",
       "4  [all, over, glow, without, adding, color, like...   \n",
       "\n",
       "                                            word2vec  \n",
       "0  [0.0308431, 0.00958252, -0.0441488, 0.144043, ...  \n",
       "1  [0.147441, -0.0728353, 0.115743, 0.39681, -0.2...  \n",
       "2  [-0.0922546, 0.0911621, 0.204285, 0.146484, 0....  \n",
       "3  [0.218658, -0.125977, 0.060791, 0.606445, -0.2...  \n",
       "4  [0.0470208, 0.14072, 0.0886587, 0.0590617, -0....  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_sentence_product_pos_neg.iloc[-4][neg_feature_columns + ['sentence']]\n",
    "df_sentence_product_pos_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster feat_0 has 7551 sentences\n",
      "Cluster feat_1 has 7608 sentences\n",
      "Cluster feat_2 has 11581 sentences\n",
      "Cluster feat_3 has 9967 sentences\n",
      "Cluster feat_4 has 16932 sentences\n",
      "Cluster feat_5 has 36171 sentences\n",
      "Cluster feat_6 has 3412 sentences\n",
      "Cluster feat_7 has 15206 sentences\n",
      "Cluster feat_8 has 1234 sentences\n",
      "Cluster feat_9 has 23926 sentences\n",
      "Cluster feat_10 has 17163 sentences\n",
      "Cluster feat_11 has 11842 sentences\n",
      "Cluster feat_12 has 3552 sentences\n",
      "Cluster feat_13 has 8062 sentences\n",
      "Cluster feat_14 has 2532 sentences\n",
      "Cluster feat_15 has 16340 sentences\n",
      "Cluster feat_16 has 13994 sentences\n",
      "Cluster feat_17 has 1751 sentences\n",
      "Cluster feat_18 has 12518 sentences\n",
      "Cluster feat_19 has 10620 sentences\n",
      "Cluster feat_20 has 1421 sentences\n",
      "Cluster feat_21 has 5258 sentences\n",
      "Cluster feat_22 has 1754 sentences\n",
      "Cluster feat_23 has 3095 sentences\n",
      "Cluster feat_24 has 15334 sentences\n",
      "Cluster feat_25 has 16759 sentences\n",
      "Cluster feat_26 has 12658 sentences\n",
      "Cluster feat_27 has 23796 sentences\n",
      "Cluster feat_28 has 228 sentences\n",
      "Cluster feat_29 has 1559 sentences\n",
      "Cluster neg_feat_0 has 2456 sentences\n",
      "Cluster neg_feat_1 has 2176 sentences\n",
      "Cluster neg_feat_2 has 2875 sentences\n",
      "Cluster neg_feat_3 has 2765 sentences\n",
      "Cluster neg_feat_4 has 6850 sentences\n",
      "Cluster neg_feat_5 has 8487 sentences\n",
      "Cluster neg_feat_6 has 714 sentences\n",
      "Cluster neg_feat_7 has 4246 sentences\n",
      "Cluster neg_feat_8 has 133 sentences\n",
      "Cluster neg_feat_9 has 8632 sentences\n",
      "Cluster neg_feat_10 has 3949 sentences\n",
      "Cluster neg_feat_11 has 2332 sentences\n",
      "Cluster neg_feat_12 has 518 sentences\n",
      "Cluster neg_feat_13 has 2147 sentences\n",
      "Cluster neg_feat_14 has 945 sentences\n",
      "Cluster neg_feat_15 has 5410 sentences\n",
      "Cluster neg_feat_16 has 3615 sentences\n",
      "Cluster neg_feat_17 has 124 sentences\n",
      "Cluster neg_feat_18 has 3384 sentences\n",
      "Cluster neg_feat_19 has 3323 sentences\n",
      "Cluster neg_feat_20 has 307 sentences\n",
      "Cluster neg_feat_21 has 1069 sentences\n",
      "Cluster neg_feat_22 has 330 sentences\n",
      "Cluster neg_feat_23 has 1019 sentences\n",
      "Cluster neg_feat_24 has 2809 sentences\n",
      "Cluster neg_feat_25 has 7142 sentences\n",
      "Cluster neg_feat_26 has 3265 sentences\n",
      "Cluster neg_feat_27 has 6434 sentences\n",
      "Cluster neg_feat_28 has 27 sentences\n",
      "Cluster neg_feat_29 has 639 sentences\n"
     ]
    }
   ],
   "source": [
    "# Write to CSV\n",
    "all_feature_columns = cluster_columns + neg_feature_columns\n",
    "for feature_name in all_feature_columns:\n",
    "    df_sentences_with_feature = df_sentence_product_pos_neg[df_sentence_product_pos_neg[feature_name] != 0]\n",
    "    print('Cluster {} has {} sentences'.format(feature_name, df_sentences_with_feature.shape[0]))\n",
    "    data_cluster_file = 'data/cluster_reviews/' + feature_name + '.txt'\n",
    "    cluster_file = open(data_cluster_file, 'w') \n",
    "    for row in df_sentences_with_feature['sentence'].as_matrix():\n",
    "        cluster_file.write(row + '\\n')\n",
    "    cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25c39a198>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAJ1CAYAAACPYqpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3X+wpfVdH/D3J2yCaCTmx0oZQJdMaJVQQ5KV0CZOjZiw\nCSpESdy0DWgJpAPGWFPHRR1N2qJLnQRFC1NSMkBGAxjjgAJGJFGbGYFsfkEgIqvZNOwQWEkM2hqm\n4Kd/3Geby82Fe75379697L5eM2fuc77n+X7O59w9e/fs+36f56nuDgAAAADM6mn7ugEAAAAAnloE\nSgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABD\n1u3rBpbrec97Xm/YsGFftwEAAACw3/j4xz/+N929fqn9nrKB0oYNG7Jt27Z93QYAAADAfqOqPj/L\nfg55AwAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAYIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAA\nABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAA\nAAAYIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAAABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQA\nAAAAGLJuXzfAU9uGLTcsuc+OraesQicAAADAarFCCQAAAIAhAiUAAAAAhgiUAAAAABgiUAIAAABg\niEAJAAAAgCECJQAAAACGCJQAAAAAGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAYIlACAAAA\nYMiSgVJVfUNV3V5Vn66qu6rqndP4O6pqZ1V9arq9dt6c86tqe1XdU1Unzxt/aVXdOT12cVXVNH5w\nVV0zjd9WVRtW/qUCAAAAsBJmWaH0SJLv6+4XJTk+yaaqOnF67KLuPn663ZgkVXVsks1JXphkU5JL\nquqgaf9Lk5yd5JjptmkaPyvJl7v7BUkuSnLhnr80AAAAAPaGJQOlnvP3092nT7d+kimnJrm6ux/p\n7s8l2Z7khKo6PMmh3X1rd3eSq5KcNm/OldP2B5KctHv1EgAAAABry0znUKqqg6rqU0keTHJzd982\nPfTWqrqjqt5bVc+exo5I8oV50++bxo6YtheOP25Odz+a5CtJnrtIH+dU1baq2rZr166ZXiAAAAAA\nK2umQKm7H+vu45McmbnVRsdl7vC152fuMLj7k7xrr3X5tT4u6+6N3b1x/fr1e/vpAAAAAFjE0FXe\nuvtvk3wkyabufmAKmv4xyXuSnDDttjPJUfOmHTmN7Zy2F44/bk5VrUvyrCQPjb0UAAAAAFbDLFd5\nW19V3zJtH5LkVUn+Yjon0m6vS/KZafv6JJunK7cdnbmTb9/e3fcnebiqTpzOj3RGkuvmzTlz2j49\nyYen8ywBAAAAsMasm2Gfw5NcOV2p7WlJru3uP6iq91XV8Zk7QfeOJG9Jku6+q6quTXJ3kkeTnNfd\nj021zk1yRZJDktw03ZLk8iTvq6rtSb6UuavEAQAAALAGLRkodfcdSV68yPibnmTOBUkuWGR8W5Lj\nFhn/apLXL9ULAAAAAPve0DmUAAAAAECgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAA\nwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAA\nAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQA\nAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAE\nAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESg\nBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBE\noAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAw\nRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAA\nMESgBAAAAMAQgRIAAAAAQ5YMlKrqG6rq9qr6dFXdVVXvnMafU1U3V9W909dnz5tzflVtr6p7qurk\neeMvrao7p8curqqaxg+uqmum8duqasPKv1QAAAAAVsIsK5QeSfJ93f2iJMcn2VRVJybZkuSW7j4m\nyS3T/VTVsUk2J3lhkk1JLqmqg6ZalyY5O8kx023TNH5Wki939wuSXJTkwhV4bQAAAADsBUsGSj3n\n76e7T59uneTUJFdO41cmOW3aPjXJ1d39SHd/Lsn2JCdU1eFJDu3uW7u7k1y1YM7uWh9IctLu1UsA\nAAAArC0znUOpqg6qqk8leTDJzd19W5LDuvv+aZcvJjls2j4iyRfmTb9vGjti2l44/rg53f1okq8k\nee4ifZxTVduqatuuXbtmaR0AAACAFTZToNTdj3X38UmOzNxqo+MWPN6ZW7W0V3X3Zd29sbs3rl+/\nfm8/HQAAAACLGLrKW3f/bZKPZO7cRw9Mh7Fl+vrgtNvOJEfNm3bkNLZz2l44/rg5VbUuybOSPDTS\nGwAAAACrY5arvK2vqm+Ztg9J8qokf5Hk+iRnTrudmeS6afv6JJunK7cdnbmTb98+HR73cFWdOJ0f\n6YwFc3bXOj3Jh6dVTwAAAACsMetm2OfwJFdOV2p7WpJru/sPqurPk1xbVWcl+XySNyRJd99VVdcm\nuTvJo0nO6+7HplrnJrkiySFJbppuSXJ5kvdV1fYkX8rcVeIAAAAAWIOWDJS6+44kL15k/KEkJz3B\nnAuSXLDI+LYkxy0y/tUkr5+hXwAAAAD2saFzKAEAAACAQAkAAACAIQIlAAAAAIYIlAAAAAAYIlAC\nAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAAABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGCJQ\nAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAYIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAAABgi\nUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAY\nIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAAABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAA\nGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAYIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAA\nABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAA\nAAAYIlACAAAAYIhACQAAAIAhAiUAAAAAhgiUAAAAABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQA\nAAAAGCJQAgAAAGCIQAkAAACAIUsGSlV1VFV9pKrurqq7qupt0/g7qmpnVX1qur123pzzq2p7Vd1T\nVSfPG39pVd05PXZxVdU0fnBVXTON31ZVG1b+pQIAAACwEmZZofRokrd397FJTkxyXlUdOz12UXcf\nP91uTJLpsc1JXphkU5JLquqgaf9Lk5yd5JjptmkaPyvJl7v7BUkuSnLhnr80AAAAAPaGJQOl7r6/\nuz8xbf9dks8mOeJJppya5OrufqS7P5dke5ITqurwJId2963d3UmuSnLavDlXTtsfSHLS7tVLAAAA\nAKwtQ+dQmg5Fe3GS26aht1bVHVX13qp69jR2RJIvzJt23zR2xLS9cPxxc7r70SRfSfLckd4AAAAA\nWB0zB0pV9cwkv5vkp7r74cwdvvb8JMcnuT/Ju/ZKh4/v4Zyq2lZV23bt2rW3nw4AAACARcwUKFXV\n0zMXJv1Wd38wSbr7ge5+rLv/Mcl7kpww7b4zyVHzph85je2ctheOP25OVa1L8qwkDy3so7sv6+6N\n3b1x/fr1s71CAAAAAFbULFd5qySXJ/lsd7973vjh83Z7XZLPTNvXJ9k8Xbnt6MydfPv27r4/ycNV\ndeJU84wk182bc+a0fXqSD0/nWQIAAABgjVk3wz4vT/KmJHdW1aemsZ9L8saqOj5JJ9mR5C1J0t13\nVdW1Se7O3BXizuvux6Z55ya5IskhSW6abslcYPW+qtqe5EuZu0ocAAAAAGvQkoFSd380yWJXXLvx\nSeZckOSCRca3JTlukfGvJnn9Ur0AAAAAsO8NXeUNAAAAAARKAAAAAAwRKAEAAAAwRKAEAAAAwBCB\nEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMWbevG4ADwYYtNyy5z46t\np6xCJwAAALDnrFACAAAAYIgVSgDAmmR1JwDA2mWFEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADA\nEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAA\nwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAA\nAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQA\nAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAE\nAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESg\nBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADFkyUKqqo6rq\nI1V1d1XdVVVvm8afU1U3V9W909dnz5tzflVtr6p7qurkeeMvrao7p8curqqaxg+uqmum8duqasPK\nv1QAAAAAVsIsK5QeTfL27j42yYlJzquqY5NsSXJLdx+T5JbpfqbHNid5YZJNSS6pqoOmWpcmOTvJ\nMdNt0zR+VpIvd/cLklyU5MIVeG0AAAAA7AVLBkrdfX93f2La/rskn01yRJJTk1w57XZlktOm7VOT\nXN3dj3T355JsT3JCVR2e5NDuvrW7O8lVC+bsrvWBJCftXr0EAAAAwNoydA6l6VC0Fye5Lclh3X3/\n9NAXkxw2bR+R5Avzpt03jR0xbS8cf9yc7n40yVeSPHeR5z+nqrZV1bZdu3aNtA4AAADACpk5UKqq\nZyb53SQ/1d0Pz39sWnHUK9zb1+nuy7p7Y3dvXL9+/d5+OgAAAAAWMVOgVFVPz1yY9Fvd/cFp+IHp\nMLZMXx+cxncmOWre9COnsZ3T9sLxx82pqnVJnpXkodEXAwAAAMDeN8tV3irJ5Uk+293vnvfQ9UnO\nnLbPTHLdvPHN05Xbjs7cybdvnw6Pe7iqTpxqnrFgzu5apyf58LTqCQAAAIA1Zt0M+7w8yZuS3FlV\nn5rGfi7J1iTXVtVZST6f5A1J0t13VdW1Se7O3BXizuvux6Z55ya5IskhSW6abslcYPW+qtqe5EuZ\nu0ocAAAAAGvQkoFSd380yRNdce2kJ5hzQZILFhnfluS4Rca/muT1S/UCAAAAwL43dJU3AAAAABAo\nAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwR\nKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAM\nESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAA\nDBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAA\nAAwRKAEAAAAwRKAEAAAAwJB1+7oBYMyGLTcsuc+OraesQicAAAAcqKxQAgAAAGCIQAkAAACAIQ55\nOwA5ZAoAAADYE1YoAQAAADBEoAQAAADAEIe8AQAOhwYAYIgVSgAAAAAMESgBAAAAMESgBAAAAMAQ\ngRIAAAAAQwRKAAAAAAxxlTeAJbj6FQAAwONZoQQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESg\nBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBE\noAQAAADAkHX7ugEAYHk2bLlhyX12bD1lFToBAOBAY4USAAAAAEOWXKFUVe9N8gNJHuzu46axdyQ5\nO8muabef6+4bp8fOT3JWkseS/GR3f2gaf2mSK5IckuTGJG/r7q6qg5NcleSlSR5K8qPdvWOFXh8H\nIL+xBwAAgL1rlhVKVyTZtMj4Rd19/HTbHSYdm2RzkhdOcy6pqoOm/S/NXAh1zHTbXfOsJF/u7hck\nuSjJhct8LQAAAACsgiUDpe7+syRfmrHeqUmu7u5HuvtzSbYnOaGqDk9yaHff2t2duRVJp82bc+W0\n/YEkJ1VVjbwIAAAAAFbPnpxD6a1VdUdVvbeqnj2NHZHkC/P2uW8aO2LaXjj+uDnd/WiSryR57mJP\nWFXnVNW2qtq2a9euxXYBAAAAYC9bbqB0aZLnJzk+yf1J3rViHT2J7r6suzd298b169evxlMCAAAA\nsMCyAqXufqC7H+vuf0zyniQnTA/tTHLUvF2PnMZ2TtsLxx83p6rWJXlW5k7ODQAAAMAatKxAaTon\n0m6vS/KZafv6JJur6uCqOjpzJ9++vbvvT/JwVZ04nR/pjCTXzZtz5rR9epIPT+dZAgAAAGANWrfU\nDlX1/iTfm+R5VXVfkl9K8r1VdXySTrIjyVuSpLvvqqprk9yd5NEk53X3Y1OpczN3xbhDktw03ZLk\n8iTvq6rtmTv59+aVeGEAAAAA7B1LBkrd/cZFhi9/kv0vSHLBIuPbkhy3yPhXk7x+qT4AAAAAWBv2\n5CpvAAAAAByABEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESgBAAA\nAMCQdfu6AYADxYYtN8y0346tp+zlTgAAAPaMFUoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEME\nSgAAAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABD\nBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMGTdvm4AANh/bNhyw0z7\n7dh6yl7uBACAvckKJQAAAACGWKEEcICbZUWJ1SQAAMB8VigBAAAAMESgBAAAAMAQgRIAAAAAQwRK\nAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBk3b5uANg3Nmy5Yab9dmw9\nZS93AgAAwFONFUoAAAAADBEoAQAAADBEoAQAAADAEOdQ2stmOU+Nc9QAAAAATyVWKAEAAAAwRKAE\nAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESg\nBAAAAMAQgRIAAAAAQwRKAAAAAAxZt68bAGD/sGHLDUvus2PrKavQCQAAsLdZoQQAAADAEIESAAAA\nAEMESgAAAAAMESgBAAAAMESgBAAAAMCQJQOlqnpvVT1YVZ+ZN/acqrq5qu6dvj573mPnV9X2qrqn\nqk6eN/7Sqrpzeuziqqpp/OCqumYav62qNqzsSwQAAABgJc2yQumKJJsWjG1Jckt3H5Pklul+qurY\nJJuTvHCac0lVHTTNuTTJ2UmOmW67a56V5Mvd/YIkFyW5cLkvBgAAAIC9b8lAqbv/LMmXFgyfmuTK\nafvKJKfNG7+6ux/p7s8l2Z7khKo6PMmh3X1rd3eSqxbM2V3rA0lO2r16CQAAAIC1Z7nnUDqsu++f\ntr+Y5LBp+4gkX5i3333T2BHT9sLxx83p7keTfCXJcxd70qo6p6q2VdW2Xbt2LbN1AAAAAPbEuj0t\n0N1dVb0SzczwXJcluSxJNm7cuCrPuZZs2HLDkvvs2HrKKnQCAAAAHMiWu0LpgekwtkxfH5zGdyY5\nat5+R05jO6ftheOPm1NV65I8K8lDy+wLAAAAgL1suYHS9UnOnLbPTHLdvPHN05Xbjs7cybdvnw6P\ne7iqTpzOj3TGgjm7a52e5MPTeZYAAAAAWIOWPOStqt6f5HuTPK+q7kvyS0m2Jrm2qs5K8vkkb0iS\n7r6rqq5NcneSR5Oc192PTaXOzdwV4w5JctN0S5LLk7yvqrZn7uTfm1fklQEAAACwVywZKHX3G5/g\noZOeYP8LklywyPi2JMctMv7VJK9fqg8AAAAA1oblHvIGAAAAwAFKoAQAAADAEIESAAAAAEMESgAA\nAAAMESgBAAAAMESgBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoA\nAAAADBEoAQAAADBEoAQAAADAkHX7ugEAAGDt2LDlhiX32bH1lFXoBIC1zAolAAAAAIZYoQQAwAHB\nyhsAWDlWKAEAAAAwRKAEAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADDEVd6ANcUVeAAAANY+K5QA\nAAAAGCJQAgAAAGCIQAkAAACAIQIlAAAAAIYIlAAAAAAYIlACAAAAYMi6fd3ASlqpy43PUmfWWgAA\nAAD7GyuUAAAAABgiUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGLJfXeUNAAAA2L+t1BXe2TNW\nKAEAAAAwRKAEAAAAwBCBEgAAAABDnEMJAIA1y3kyAGBtskIJAAAAgCECJQAAAACGCJQAAAAAGCJQ\nAgAAAGCIQAkAAACAIa7yBgAAALAHDsSrklqhBAAAAMAQgRIAAAAAQwRKAAAAAAwRKAEAAAAwRKAE\nAAAAwBCBEgAAAABDBEoAAAAADBEoAQAAADBEoAQAAADAEIESAAAAAEMESgAAAAAMESgBAAAAMESg\nBAAAAMAQgRIAAAAAQ9bt6wYAAABYGRu23LDkPju2nrIKnQD7OyuUAAAAABhihRIA+61Zfkub+E0t\nAACM2qMVSlW1o6rurKpPVdW2aew5VXVzVd07fX32vP3Pr6rtVXVPVZ08b/ylU53tVXVxVdWe9AUA\nAADA3rMSh7y9sruP7+6N0/0tSW7p7mOS3DLdT1Udm2Rzkhcm2ZTkkqo6aJpzaZKzkxwz3TatQF8A\nAAAA7AV74xxKpya5ctq+Mslp88av7u5HuvtzSbYnOaGqDk9yaHff2t2d5Kp5cwAAAABYY/Y0UOok\nf1xVH6+qc6axw7r7/mn7i0kOm7aPSPKFeXPvm8aOmLYXjn+dqjqnqrZV1bZdu3btYesAAAAALMee\nnpT7Fd29s6q+NcnNVfUX8x/s7q6q3sPnmF/vsiSXJcnGjRtXrC4AAAAAs9ujFUrdvXP6+mCS30ty\nQpIHpsPYMn19cNp9Z5Kj5k0/chrbOW0vHAcAAABgDVp2oFRV31RV37x7O8mrk3wmyfVJzpx2OzPJ\nddP29Uk2V9XBVXV05k6+fft0eNzDVXXidHW3M+bNAQAAAGCN2ZND3g5L8ntzGVDWJfnt7v7DqvpY\nkmur6qwkn0/yhiTp7ruq6tokdyd5NMl53f3YVOvcJFckOSTJTdMNAAAAgDVo2YFSd/91khctMv5Q\nkpOeYM4FSS5YZHxbkuOW2wsAAAAAq2dPr/IGAAAAwAFGoAQAAADAEIESAAAAAEMESgAAAAAMESgB\nAAAAMGTZV3kDAAD2zIYtNyy5z46tp6xCJwAwxgolAAAAAIYIlAAAAAAYIlACAAAAYIhzKAEAAHuF\nc0QB7L+sUAIAAABgiEAJAAAAgCECJQAAAACGCJQAAAAAGOKk3AAAADzOLCdUT5xUHQ5kAiVgj7mC\nCwAAwIHFIW8AAAAADLFCiTXBkloAAGApVsbD2iFQAgAA4IAimII9J1ACAAAADjiOlNkzzqEEAAAA\nwBArlABglVlmDwDAU50VSgAAAAAMESgBAAAAMMQhbwAAJHE4JgAwO4ESAAAAsFf5pcX+R6AEAMCK\n8x8HANi/OYcSAAAAAEMESgAAAAAMccgbsF9yqAUAAMDeI1ACANgHBN8AwFOZQ94AAAAAGGKFEgAA\nsKbNsqIvsaoPYDVZoQQAAADAECuUAACewqzcAAD2BYESAADAMji5PnAgc8gbAAAAAEMESgAAAAAM\nESgBAAAAMESgBAAAAMAQJ+UGeApyEtDV53sOAABfY4USAAAAAEMESgAAAAAMccgbAMCMHPoIADDH\nCiUAAAAAhlihBMCaYxUIAACsbVYoAQAAADBEoAQAAADAEIe8wZNw2A0AAAB8PSuUAAAAABhihRIA\nAADsY7McHZE4QoK1Q6AEAAAALMppQHgiAiUAAIB9yH/Ygaci51ACAAAAYIhACQAAAIAhDnkDAIAB\nTpwLAAIlAAAAgP3O3j4/m0PeAAAAABhihRIAAHDAcEU1gJVhhRIAAAAAQwRKAAAAAAxxyBsAAAAs\n01o8jHIt9sT+Z80ESlW1KcmvJzkoyf/o7q37uCUAYD/hgzUAwMpaE4e8VdVBSf5bktckOTbJG6vq\n2H3bFQAAAACLWSsrlE5Isr27/zpJqurqJKcmuXufdgUAAE8RVuKxVnlvwv6puntf95CqOj3Jpu5+\n83T/TUle1t0/sWC/c5KcM939Z0nuWaL085L8zQq1uRZr6Wn1a+lp9WvpafVr6Wn1a+lp9WvpafVr\n6Wn1a+lp9WvpafVr6Wn1a+lp9Wutdk/f3t3rlyq0VlYozaS7L0ty2az7V9W27t64Es+9FmvpafVr\n6Wn1a+kxQbVIAAAfP0lEQVRp9WvpafVr6Wn1a+lp9WvpafVr6Wn1a+lp9WvpafVr6Wn1a63FnpI1\ncg6lJDuTHDXv/pHTGAAAAABrzFoJlD6W5JiqOrqqnpFkc5Lr93FPAAAAACxiTRzy1t2PVtVPJPlQ\nkoOSvLe771qB0jMfHvcUraWn1a+lp9WvpafVr6Wn1a+lp9WvpafVr6Wn1a+lp9WvpafVr6Wn1a+l\np9WvtRZ7Whsn5QYAAADgqWOtHPIGAAAAwFOEQAkAAACAIQIlAAAAAIYIlAAAAAAYsl8FSjXnZVX1\nw9PtZVVVK/wc37GMOU9fZOx5y6jztKp62rT9jKp6SVU9Z7TOInXP3dMaU51nTj19yzLmPmP+n1VV\nvbKq3l5Vrxms812jz71EvW/b/XqqakNVnV5Vxy2z1saqel1V/dBy3kcA7J+q6rDp38+XVNVhK1z7\nmStZb0+txOeWqc4PrUSdqdZKfJZ6QVX9SFUdu4y5w5+blqi3bt72M6fPH8t6jVW1vqpeXFXftdbe\nSwDse/tNoFRVr05yb5J3JHntdHtnknunx1bKHw309Mqqui/J/VX1R1W1YTl1plqnJbk/yc6qOjXJ\n/0zyq0nuqKofHKjz0wtub0/yn3bfH+zpknnbr0hyd5J3Jbmzql47UivJx5LsDm5+JskFSQ5J8tNV\n9SsDdT5ZVfdW1X9ezoe6+apqS5I/TXJrVb05yR8meU2Sa0a+V1X1r6pqW5KtSd6b5Jwkl1fVn1TV\nUcvo6+SqurSqrp9ul1bVptE6SzzHLy6jp7MWvMdTVf9usE5V1Ruq6vXT9klVdXFVnbs7TF2uqvrw\nMuc9b8H9fzv1dM5oYD0Fis+ZttdX1VVVdWdVXVNVRw7UeXdVvXzkuZ+k1nOq6her6s3T9/znq+oP\nqupXq+rZg7VeWVW/WVXXVdUHq2prVb1gmX15ny+D9/kT1lqr7/Pjq+rWJH+S5L9Otz+tqlur6iXL\nqbmIuwd7+ufT83+hqi6b//2pqtsHa728qj5bVXfV3C/5bk7ysan2vxio88MLbj+S5LLd9wd7+oV5\n28dW1V8m+XhV7aiqlw3U+cjuvzdV9aYkN+ZrnxHeOtJTkr+pqj+efr7sUbhUVT+W5IGq+sua+6Xc\nHUkuTPLpqnrjQJ1jq+qPk/x5ktuSvCdzn++uqKpnLaOv76iqn51+rlw8bX/naJ0nqf/jy+zppFoQ\nlC3n35qqOqGqvnvaPrbmPlePfhZerO5Ve1pjqvOKqaeh/xNNf28PnbYPqap3VtXvV9WFo++DqvrJ\nWsbn3ieo9YyqOqOqvn+6/6+nn8vn1SK/yF+i1vOr6j9W1a9P/+78+92veRl9eZ8vg/f5E9Zak+/z\nr6vd3StRZ5+rqs8meU1371gwfnSSG7t75r/MVXXxEz2U5MzunumbX1UfS/Jj3X1XVZ2e5FeSvKm7\nb62qT3b3iwd6+mTmPqgckuTTSb67u++pqm9P8rvdvXHGOn+XuQ89d02vJ0l+KsmvJUl3v3Ogp090\n90um7Y8keXt3f6Kqnp/k2ll7muZ/pruPm7a3Jfme7v6Hmvst2ye6e6aVR9P36U1J3pjkR5P87yTv\nT3L1wvfGDLXuSrIxyTcm2ZHk+d29q6q+Kcltu/udsadXT3OPTvLu7n5dVb0qyc9098w/9Krq15L8\n0yRXJblvGj4yyRlJ7u3ut81aa4nn+V/d/W0z7vvLSV6R5BNJfjDJr3X3b0yP/f/3yIy1LknyrUme\nkeThJAcnuT7JKUkemPX1VdUdC4cy9327J0lmfT9Ntea/z38hyfck+e0kP5Dkvu7+DwO17u7uY6ft\na5LcmuR3knx/kn/T3a+asc6uJJ9Psj7JNUne392fnLWPBbVuTHJnkkOTfOe0fW2SVyV5UXefOmOd\nX0nyT5LckuS0JJ9L8pdJzk3yy939OwM9eZ/PVsf7fPae1tz7fKr3qSRv6e7bFoyfmOS/d/eLZqzz\nRL/kqCQ/390zr06pqo8m+S+Z+3N7c5IfT/JD3f1Xy/jscnuSs5I8M8nvJzmtuz9ac2HZb3T3TIFh\nVf3fJB9K8mC+9tnl9CQfSNLdPXOou+C9fkOS3+zum6rqhMz9vf6XM9aZ/7nlY0k2dfdDVfWNSW4d\n/Pt3Z5LzM/fZZVOSj2bus8t13f0Ps9aZV+uVSb45c58XXzz92R2W5OaBz1O3Zu4z7z3T9+a87j6z\nqs5OcnJ3nz7Q089Or+3qPP5n+ubMfT7bOmutJ3mOmX+eT/v/ZJLzknw2yfFJ3tbd102Pjf5M/6XM\nfUZfl+TmJC9L8pHM/Xz5UHdfMGOd6xcOZe7P8sNJ0t0zr8qrqtu7+4Rp++zMvdbfS/LqJL8/6/d8\n+iz8ou5+tKouS/J/Mvf37qRpfOZAt6q+krnP5X+Vuff373T3rlnnL6j1W5n7fn9jkr/N3M+YD059\n/b/2zj3Yrqq+459fXpBAiMYwPIUYFBmBgFgYQKdCZVRwpCKPCkqBju1AQSLV+qg6Wuk4g4JWQVAY\npFWLrQVbqFMQiyLVCORhQsIbEpMQKCoaEkViHr/+sfa92Tk5Nznr3HXXXmfz/cysuefsnfM539/N\nPufus85aa5u7n9Oj52LC37m7CYMRflb5TgH+2t3visik47w3j47z3l3FHeddcfdWNMLopAldtk8C\nHo90rSOMIjmnS/tVhGdxx/2DCSf67yB0ksRk+lnt9tKOfT27gP0IJ/aXAVOqbcv6/J0vHClDH/XN\nBQ6pbt8OvLS6vXNnvb1mqu4fBXye8MY+NzLT/dXP8YST2HEj/R/04qm56r+3ByIzPTrCdiN80I5x\nrR2hrQM2RniWDL32CKPM/hv4Qudx26ur+jkReBaYVN2fUP899uC5FfgmcBCwPzATWFXd3j8yU/21\ntxDYpZZxSaTrkdrtBR37FsVmInQefILQQfww8EngwMhMi2rH0OpRZFpSuz0B+El1+6Uxr5fqMTrO\ne/PoOO/dVdxxXj1uxOOZiHMX4AXg0up309nWRGbqPHc5nnCOdTSjO3d5qGNfzLnLkYROvAtq25bH\n/r47n7fz/z7mtUw4Id+nuv1DYOfq9nji/7bXM00GziB8aHgWuDHStah2+6mOfTHvL53HQT3jQ5GZ\nHgUmdtk+aXuvgS7//v4R2hJgfWSmJcCu1e2ZwHzCh+2o46DmGk/40LcW2K32fxnzO19IeE8/Dnhj\n9fPp6vYbIzPVX3vzgN2r27sQ8Z5e/7/ufM12vn56yUSYHfNm4Hrgl4Rz/nOAqZGuoXP0CcAzwPjq\nvkX+zpfUHjsFuKu6vV8fx4GOcx3nrT/Ou7XhOdYt4GuEYdT/SjihBng5oVf4+kjXPMKJ4dzOHWb2\nqQjPBjPb093/D8DDSKU3Ad8FDojMhJmNc/fNwF/Uto0nvFH1hLuvBE63MG3u+2b2hdgcNQ6qviE3\nYKaZvdTdf2NhykbPmSrOB/7FzBYTOm/mm9ndwKHAZyI8W03NcPf7gPssTO3748hMC83sRsKb0p3A\nP5vZ7cCfEDeFYL6ZXU/oeT+ZMLWB6lvM8ZGZXjCzI919Xsf2IwkfKGJYQxjp9kznDjNb1eXfj8QE\nd98I4O5rLEzBvNbM/p3442DIs8HM5rn7H6r7G81sc68Sdz/ZzE4BrgUud/dbzWyDu6+IzAMw2cxe\nS/jjMNHdf1fLuCnSdZeZfZowWvEuMzvF3f/DzI4HnovweJXhUcKHyEstrB92JqGjI2b6zTgLU1qm\nArua2Ux3/7mZvYy4/7/NZjbd3X8N7E11bFfvCbFr2ek47wEd5wN/nAPcVo2S+Tpbn7v8OeEEtFcW\nAv/p7gs6d1iYsh2FmU1z9+cA3P2HFqaY3QzErsNTn8L50Y59Mecu8yyM6n2fhRHRH6Y6PvpgVvUN\nuQH7mtkUd3++2hczheAS4A4zu5nQ2fkDM/seYSTjDZGZho8dDyOSvg1828JUi3dEulZWI+mmAg+b\n2RWEzqkTCB/aeuUJM/sE4dzlncAiAAvTLGKn5m4mvF4635v2qvb1yh7AW4DfdGw3wheTMYxz998C\nVO8FxwE3WRj5H/ta3ujum4DnzewJd19beX8f855OGBU/B/gYYQT7IjP7vbv/KDIPbHnPG0f4IPnL\nKtPvzGxjhGepmZ3n7jcQpk3+kbvPN7MDgQ2Rmbz6HHMH4bUzkTDi5UzgcsJo1F4ZZ2aTCOfoU4Bp\nwK8JI36jpgIRPqxvqh67axV0pUVOKULHea/oOO+dEo/zbRltj1RJjTCM/SPAlVX7CPCaPjzTqUbv\njDLPCYRhcp3bpxGGoMe4jqT69qtj+0zgPX3m24WwDtPdfT5+/442sdo+A3hnH77xhBfcHOADhClr\nL4l0nJXweJpAePG/q7p9LHAV8CGqb+979EwkTIe4CvhLtvQQTyZ+FMERhLUMHqR6oyIMY70HeF2k\n6x+Ao0bYd1mE57t0+Uah8m+OzHQb1TcpHdv3BO7r4/9wF8IItVsI03b6OQ5+2NH2qra/DJgf6ZpI\nWOdtZdU2E0bK3AjsF+EZ9bcJNdeZhG89ngFOBf6HMJR5NfBXEZ4/I5xEfb+q7W3V9t2J/4Zdx3mc\nT8f5jl3FHec154nAVwhTwv6run1SpOPVwIwR9u0R6ToLOLrL9v2A6yJdJ9PlfIrwpdqH+vx97U3o\ncOl3dPUbO9rQt/d7EKZ1xbimARcAXyCcd34YOKiPTB/sp5YRXLsROu8+QvjQcGr1/vXlodd1j56X\nENb0+i5hXcuptZq3OT524Hor8Hj13ndt1W6vtr01wnM98IYR9sX+nfkBcHjHtgmEzt1Nka572TLq\nvz6afRqRo/qqx+1LmE1wFbCyz+Pg58AywrTcZWx5T9+VuFGZ04B/IkzfuZfw4XoZYY3RbT7j7MA1\n4nt6t/eJHbguqXKsAC4mfPF7HWEkxicjPHMIo3+uI4yAPa/avjuRn490nOs4r1ytPs67tdasodQr\nZnazu59akkuZ8rsGPZOZ7QnsU91d7dUouCYws8kw/K1q57593H11gufYhdCJ94s+H38YcIy7f2W0\nWWrO8cBOvuWb7djHTyOMenm2j8fu6tU3TimoajEPI2QmEObZr3b3mG+zsbAQ8yzCVJ01CXLpOI97\nvI7z7fuKPM57fM4r3T12oecx85TqUqb8rl49FkavH0XtPR2Y52HEQ3YsXCBgY7e/K2b2enf/SYRr\nJ3df32X7DMIH3CV9Znwb8Hp3/7t+Hj+Ccwqhk3l55ON2A15B6Ix40ruM+u3BcaCHEadJMLO9Adz9\nKQuL2Z9A6JiIvXjAwYRBCUvd/eFRZtJxHp9Rx/n2fcUd59u4X4QdSlELSuZwKVN+VxszmdlBqd4g\nUrmUKb+rTZnMbKK7b+jYNsPdf9WUS5nyu9qeqcfni1o8daw9pbqUKb9rtJ5UHccpO6BLdClTflfq\nLzWEaCujujzxgJKyBy2VS5nyu9qY6Y4kKdK6lCm/a+AzWbgs+5PA02Z2h5nNbNqlTPldbc8khADi\n1qTM4SnVpUz5XVEeM5ttZveY2Sozu9bC2j5D+3oeTZLKU/37QxO6UtVXYqa2/86T1deNNi3KLUTr\nMbMvjbSLsN5Bdpcy5Xe1PRNh3Y63eLiQwWmECwic7e73VL4mXMqU39X2TEK8KDCzvxlpF9XisDk9\npbqUKb8rZSbgasL6gfcA7wV+bGYnu/sTxC2gnMoDcE1CV6pcJWZq++88ZX3b8GLsUEp5wpfKpUz5\nXYOa6TzCguXbzGEmLDobQyqXMuV3tT3TJHd/AMDdbzKzh4DvmFk/V3ZK5VKm/K62Z4qhzX/7UrqU\nKb+rF89nCBeB6XbVpZjZEqk8pbqUKb8rZaap7j50dc7LzWwBcLuZnU3c34dUnlJdypTflTLTtvgo\nV/UurQFztrcNeHNulzKpvlQewtUajh1h3/Jea0rpUibVNwaZ5gN7dmzbl3DZ6nVNuJRJ9aXO1OE4\nfXvbgHNzekp1KdNg1ke41HnXK3QCqyJqSuIp1aVMA1/fYmBax7bZwGPAs7k9pbqUabDr6+ofraC0\nRpfLFtLnpYdTuZRJ9aXyANOJvOTkWLuUSfWNQaYT6HKZVsJlXT/WhEuZVF/qTB2P7/b3oZ/LMCfx\nlOpSpsGsD3g1MGOEfXvk9pTqUqaBr+8s4Ogu2/cDrsvtKdWlTINdX7fWmqu8mdmZhF/WG4D/re2a\nCmx29zfldimT6kudqVfM7GZ3P7UklzLldylTfpcy5XcNciYzOxE4CTgD+Lfart2A17j7UT0+XxJP\nqS5lGuz6esXMrnT395XiKdWlTPldypTfpUz5Xf162rSG0lzgaWAGcEVt+zrg/oZcypTf1fZMvTKr\nQJcy5XcpU36XMuV3DXKmpwjT6E4GFtS2rwMuiXi+VJ5SXcqU35UyU6+8vjBPqS5lyu9SpvwuZcrv\n6svTmg4ld18BrACOKcWlTPldbc8U87QFupQpv0uZ8ruUKb9rYDO5+2JgsZnd6O4b+n6yRJ5SXcqU\n35UykxBCiPYSu3p98ZjZ0WY2z8x+a2Z/MLNNZra2SZcy5Xe1PZMQQohWMdPMbjKzB81s2VBr0FOq\nS5nyu1JmEkII0TJa16EEXEW4RPVjwGTgvcCXG3YpU35X2zPtiEG9tHBuV4mZUrqUKb9LmfK72pDp\nBuAawqWrjwe+Dnyzj+dN5SnVpUz5XSkz7Yg2vyekdClTfpcy5XcpU35Xf57RrupdWgPmVz/vr23r\n9+peSVzKpPrGINOc7W0D3pzbpUyqr9RMba+vxExtry9lpurfL6h+Lunc1oSnVJcyDXx9p29vG3Bu\nTk+pLmVSfaVmant9JWYqtb6tHP08qOQG3A1MInyD8lnCwoGLm3Qpk+obg0zdLuPbb+dUEpcyqb5S\nM7W9vhIztb2+lJmqx84ljBr/DnARcArwSFOeUl3KNPD1dXvdbLMtl6dUlzKpvlIztb2+EjOVWl+9\ntWZR7hpnE/7wXUT4wP5yoN9LAKdyKVN+VyszmdmZwFnAK8zs1tquqcCvm3ApU36XMuV3KVN+V9sz\ndTAHmAJcDFxKmFp0ToOeUl3KlN81ao+ZnQicBOxjZl+q7dqNMJUuq6dUlzLldylTfpcy5XelzNSN\n1nUoufsKM5sM7OXuf1+CS5nyu1qcaS7wNDADuKK2fR1wf0MuZcrvUqb8LmXK72p7pmHcfR6AmW12\n9/Oa9pTqUqb8rkSep4D5wMnAgtr2dYQv2HJ7SnUpU36XMuV3KVN+V8pM2zLaIU6lNeDtwCPA8ur+\n4cCtTbqUSfWlzqSmpqam1p4GHAM8CKys7h8GXN2Up1SXMg18fRP7edxYeUp1KZPqKzVT2+srMVOp\n9W3lHQtpk43Q6zaN2loG1BYSbMKlTKpvDDIdDcwDfgv8AdgErG3SpUyqr9RMba+vxExtry9lpsp3\nL2EadP3vw9KmPKW6lGng63sVcBOhg2rZUGvKU6pLmVRfqZnaXl+JmUqtr97G0T42uPtzHdu8YZcy\n5Xe1PdNVwJnAY8Bk4L3Alxt2KVN+lzLldylTflfbMwHg7qs6Nm1q0lOqS5nyuxJmugG4hrBmx/GE\ni5R8s0FPqS5lyu9SpvwuZcrvSplpmDZ2KD1gZmcB483sVWZ2JWHNgyZdypTf1fZMuPvjwHh33+Tu\nNwBvbdqlTPldypTfpUz5XW3PBKwys2MBN7OJZvZB4KEGPaW6lCm/K2Wmye5+J2DuvsLdPwW8rUFP\nqS5lyu9SpvwuZcrvSplpmNYsym1m33D3s4EngIOB9cC3gO8RrkqR3aVM+V1tz1TjeTObBCwys88S\nFontt4M4lUuZ8ruUKb9LmfK72p4J4Hzgi8A+wGrgDuDCBj2lupQpvytlpvVmNg54zMwuqny7Nugp\n1aVM+V3KlN+lTPldKTNtwUc5Z66URpgLuDewGJje2ZpwKZPqS52p5twf2JlwucdPAp8HXtmkS5lU\nX6mZ2l5fiZnaXl9Cz2XVz9P7qSe1p1SXMg12fTXnkYQPL/sSpl7cDBzdlKdUlzKpvlIztb2+EjOV\nWl+9WSUfeMzsYuACYBaht214F+DuPiu3S5lUX+pMHd7JwH7u/kg/jx8LlzLldylTfpcy5Xe1NZOZ\nLQFmAwvc/YimPaW6lCm/K2WmLu4p7v58KZ5SXcqU36VM+V3KlN+VMhPQnhFKQw24pjSXMqm+Mcj0\nduARYHl1/3Dg1iZdyqT6Ss3U9vpKzNT2+hJ6PgesISyQuRZYV/+Z21OqS5kGu76a8xjCqO2V1f3D\ngKub8pTqUibVV2qmttdXYqZS69vKO1qBmppa/gYsAKax9WV8lzTpUibVV2qmttdXYqa215cyU/XY\nW/p97Fh4SnUp08DXdy/w8o7XzdKmPKW6lEn1lZqp7fWVmKnU+uqtjVd5E+LFwAZ3f65jmzfsUqb8\nLmXK71Km/K62Z8Ld/3R7+83spzk9pbqUabDrq3yrOjZtinl8ak+pLmXK71Km/C5lyu9KmWmI1lzl\nTYgXGQ+Y2VnAeDN7FXAxMLdhlzLldylTfpcy5Xe1PVMv7FyYp1SXMuV3xXhWmdmxgJvZRGAO8FAf\nz5nKU6pLmfK7lCm/S5nyu1JmGkYjlIQYIMzsG9XNJ4CDgfXAtwjrGry/CZcy5XcpU36XMuV3tT1T\nJH2PfhojT6kuZcrvivGcD1wI7EO4SMnh1f1YUnlKdSlTfpcy5XcpU35XykxbGO2cOTU1tXyNsJDa\n3sBiYHpna8KlTKqv1Extr6/ETG2vL2WmyPwLS/KU6lKmMusDLqt+nj7K50riKdWlTKqv1Extr6/E\nTKXW161ZJRdCDABmdjFwATCL0LM8vAtwd5+V26VMqq/UTCldyqT6UmeKwcx+5u6vLcVTqkuZ8rt6\n8ZjZEmA2sMDdjxjFcyXxlOpSpvwuZcrvUqb8rpSZujIWvVRqampj24BrSnMpk+orNVPb6ysxU9vr\nS5mpx+c7pCRPqS5lKrM+4HPAGmAjYXrouvrPiOdK4inVpUyqr9RMba+vxEyl1tetaYSSEEIIIUSD\nmNk6tl2L5jlgPvABd1+W01OqS5kGvr5bfAdXjcvpKdWlTPldypTfpUz5XSkzbeVVh5IQQgghRHOY\n2aXAk8CNhOlz7wIOABYCF7j7cTk9pbqUabDr6+G5furux5TiKdWlTPldypTfpUz5Xf161KEkhBBC\nCNEgZrbY3Q/r2LbI3Q/vtm+sPaW6lGmw6+vhubRulTIV6VKm/C5lyu/q1zNutE8shBBCCCFGxfNm\ndoaZjavaGcAL1b6Yb/5SeUp1KVN+V8pMOyKVL2WuEl3KlN+lTPldypTf1ZdHHUpCCCGEEM3ybuBs\n4BfAM9Xt95jZZOCiBjylupQpvytlJiGEEC1jQtMBhBBCCCFezFQLG799hN0/zu0p1aVM+V0pM/WA\nFeYp1aVM+V3KlN+lTPldfXk0QkkIIYQQokHM7EAzu9PMllb3Z5vZx5vylOpSpvyulJl64OzCPKW6\nlCm/S5nyu5Qpv6svjxblFkIIIYRoEDP7EfC3wFeHFsQ0s6XufkgTnlJdypTflTjTOrZdo+M5YD7w\ngWo0VDZPqS5lUn2lZkrpUqbBrq+OprwJIYQQQjTLFHe/z2yr0eYbG/SU6lKm/K6Umf4ReBK4kTC1\n4l3AAcBC4GvAcZk9pbqUKb9LmfK7lCm/K2WmLbi7mpqampqamppaQw24beikrrp/GnBbU55SXco0\n8PUt7rJt0Uj7xtpTqkuZVF+pmdpeX4mZSq2v3rSGkhBCCCFEs1wIfBU4yMxWA+8Hzm/QU6pLmfK7\nUmZ63szOMLNxVTsDeKHaF7MGRypPqS5lyu9SpvwuZcrvSplpGK2hJIQQQgjRIGa2E2Hkx0xgOrAW\ncHf/dBOeUl3KlN+VONMs4IvAMYQPL/cAlwCrgde5e09XjUvlKdWlTKqv1EwpXco02PVt5VWHkhBC\nCCFEc5jZ7cAawjoGm4a2u/sVTXhKdSlTflfKTEIIIVpIv3Pl1NTU1NTU1NTURt+ApSV5SnUp08DX\ndyBw55ATmA18vClPqS5lUn2lZmp7fSVmKrW+etMaSkIIIYQQzTLXzA4tyFOqS5nyu1Jmug74KLAB\nwN3vJ1xlqClPqS5lyu9SpvwuZcrvSplpmAmjFQghhBBCiFHxBuBcM1sOrCdcztfdfXZDnlJdypTf\nlTLTFHe/z8zq2zY26CnVpUz5XcqU36VM+V0pMw2jDiUhhBBCiGY5sTBPqS5lyu9KmelXZnYA1dWE\nzOw04OkGPaW6lCm/S5nyu5QpvytlpmG0KLcQQgghhBBiTKmuMHQtcCzwG2A58G53X9GEp1SXMuV3\nKVN+lzLld6XMtJVXHUpCCCGEEEKIscTMdgJOA2YC04G1hOlzn27CU6pLmfK7lCm/S5nyu1JmqqMp\nb0IIIYQQQoix5hZgDbAQeKoAT6kuZcrvUqb8LmXK70qZaRiNUBJCCCGEEEKMKWa21N0PKcVTqkuZ\n8ruUKb9LmfK7UmaqMy61UAghhBBCCCE6mGtmhxbkKdWlTPldypTfpUz5XSkzDaMRSkIIIYQQQogx\nxcweBF5JWAh2PWCE9TtmN+Ep1aVM+V3KlN+lTPldKTNt5VWHkhBCCCGEEGIsMbP9u23v40pFSTyl\nupQpv0uZ8ruUKb8rZaatvOpQEkIIIYQQQgghhBAxaA0lIYQQQgghhBBCCBGFOpSEEEIIIYQQQggh\nRBTqUBJCCCGEEEIIIYQQUahDSQghhBBCCCGEEEJE8f8s8o1ziM84vQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25c3a6c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sentence_products_clusters = df_sentence_product_pos_neg[all_feature_columns + ['product_id']].groupby(['product_id']).sum()\n",
    "\n",
    "# How many results for each feature type?\n",
    "df_sentence_products_clusters.sum(axis=0).plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_feat_20</th>\n",
       "      <th>neg_feat_21</th>\n",
       "      <th>neg_feat_22</th>\n",
       "      <th>neg_feat_23</th>\n",
       "      <th>neg_feat_24</th>\n",
       "      <th>neg_feat_25</th>\n",
       "      <th>neg_feat_26</th>\n",
       "      <th>neg_feat_27</th>\n",
       "      <th>neg_feat_28</th>\n",
       "      <th>neg_feat_29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P102503</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P102504</th>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P107306</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P112400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P113608</th>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "product_id                                                                   \n",
       "P102503        8.0     7.0    12.0    14.0    11.0    32.0     1.0    12.0   \n",
       "P102504       17.0     7.0    13.0    16.0    29.0    49.0     1.0    28.0   \n",
       "P107306       12.0     9.0     3.0     0.0    21.0    33.0     3.0    19.0   \n",
       "P112400        1.0     3.0     3.0    18.0     4.0    10.0     1.0     2.0   \n",
       "P113608       12.0    26.0    19.0     8.0    23.0    68.0     0.0    25.0   \n",
       "\n",
       "            feat_8  feat_9     ...       neg_feat_20  neg_feat_21  \\\n",
       "product_id                     ...                                  \n",
       "P102503        4.0    10.0     ...               0.0          0.0   \n",
       "P102504        3.0    39.0     ...               0.0          2.0   \n",
       "P107306        2.0    32.0     ...               1.0          3.0   \n",
       "P112400        2.0     5.0     ...               0.0          0.0   \n",
       "P113608        0.0    38.0     ...               0.0          0.0   \n",
       "\n",
       "            neg_feat_22  neg_feat_23  neg_feat_24  neg_feat_25  neg_feat_26  \\\n",
       "product_id                                                                    \n",
       "P102503             0.0          1.0          3.0          6.0          5.0   \n",
       "P102504             0.0          2.0          7.0         11.0          3.0   \n",
       "P107306             0.0          3.0          6.0          6.0          2.0   \n",
       "P112400             0.0          0.0          0.0          0.0          0.0   \n",
       "P113608             0.0          5.0          0.0          3.0          8.0   \n",
       "\n",
       "            neg_feat_27  neg_feat_28  neg_feat_29  \n",
       "product_id                                         \n",
       "P102503             4.0          0.0          1.0  \n",
       "P102504             8.0          0.0          0.0  \n",
       "P107306             6.0          0.0          2.0  \n",
       "P112400             0.0          0.0          0.0  \n",
       "P113608             9.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentence_products_clusters.head() # Unnormalized, Uncentered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_feat_20</th>\n",
       "      <th>neg_feat_21</th>\n",
       "      <th>neg_feat_22</th>\n",
       "      <th>neg_feat_23</th>\n",
       "      <th>neg_feat_24</th>\n",
       "      <th>neg_feat_25</th>\n",
       "      <th>neg_feat_26</th>\n",
       "      <th>neg_feat_27</th>\n",
       "      <th>neg_feat_28</th>\n",
       "      <th>neg_feat_29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P102503</th>\n",
       "      <td>0.142359</td>\n",
       "      <td>0.124564</td>\n",
       "      <td>0.213538</td>\n",
       "      <td>0.249128</td>\n",
       "      <td>0.195743</td>\n",
       "      <td>0.569435</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>0.213538</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.177948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>0.053385</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>0.088974</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P102504</th>\n",
       "      <td>0.141368</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>0.108105</td>\n",
       "      <td>0.133052</td>\n",
       "      <td>0.241156</td>\n",
       "      <td>0.407471</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.232841</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>0.324314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.058210</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>0.066526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P107306</th>\n",
       "      <td>0.125587</td>\n",
       "      <td>0.094191</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219778</td>\n",
       "      <td>0.345365</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.198847</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P112400</th>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.138343</td>\n",
       "      <td>0.345857</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.172929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P113608</th>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.177571</td>\n",
       "      <td>0.129763</td>\n",
       "      <td>0.054637</td>\n",
       "      <td>0.157082</td>\n",
       "      <td>0.464415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020489</td>\n",
       "      <td>0.054637</td>\n",
       "      <td>0.061467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feat_0    feat_1    feat_2    feat_3    feat_4    feat_5  \\\n",
       "product_id                                                               \n",
       "P102503     0.142359  0.124564  0.213538  0.249128  0.195743  0.569435   \n",
       "P102504     0.141368  0.058210  0.108105  0.133052  0.241156  0.407471   \n",
       "P107306     0.125587  0.094191  0.031397  0.000000  0.219778  0.345365   \n",
       "P112400     0.034586  0.103757  0.103757  0.622543  0.138343  0.345857   \n",
       "P113608     0.081956  0.177571  0.129763  0.054637  0.157082  0.464415   \n",
       "\n",
       "              feat_6    feat_7    feat_8    feat_9     ...       neg_feat_20  \\\n",
       "product_id                                             ...                     \n",
       "P102503     0.017795  0.213538  0.071179  0.177948     ...          0.000000   \n",
       "P102504     0.008316  0.232841  0.024947  0.324314     ...          0.000000   \n",
       "P107306     0.031397  0.198847  0.020931  0.334900     ...          0.010466   \n",
       "P112400     0.034586  0.069171  0.069171  0.172929     ...          0.000000   \n",
       "P113608     0.000000  0.170741  0.000000  0.259526     ...          0.000000   \n",
       "\n",
       "            neg_feat_21  neg_feat_22  neg_feat_23  neg_feat_24  neg_feat_25  \\\n",
       "product_id                                                                    \n",
       "P102503        0.000000          0.0     0.017795     0.053385     0.106769   \n",
       "P102504        0.016631          0.0     0.016631     0.058210     0.091473   \n",
       "P107306        0.031397          0.0     0.031397     0.062794     0.062794   \n",
       "P112400        0.000000          0.0     0.000000     0.000000     0.000000   \n",
       "P113608        0.000000          0.0     0.034148     0.000000     0.020489   \n",
       "\n",
       "            neg_feat_26  neg_feat_27  neg_feat_28  neg_feat_29  \n",
       "product_id                                                      \n",
       "P102503        0.088974     0.071179          0.0     0.017795  \n",
       "P102504        0.024947     0.066526          0.0     0.000000  \n",
       "P107306        0.020931     0.062794          0.0     0.020931  \n",
       "P112400        0.000000     0.000000          0.0     0.000000  \n",
       "P113608        0.054637     0.061467          0.0     0.000000  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_cluster_normalized = normalize(df_sentence_products_clusters) # Normalized and not Centered\n",
    "df_products_cluster_normalized = pd.DataFrame(data=products_cluster_normalized, columns=all_feature_columns, index=df_sentence_products_clusters.index)\n",
    "df_products_cluster_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run one time\n",
    "df_products_cluster_normalized.to_csv('data/product_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat_5     0.569435\n",
       "feat_10    0.284717\n",
       "feat_3     0.249128\n",
       "feat_2     0.213538\n",
       "feat_7     0.213538\n",
       "Name: P102503, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df_products_cluster_normalized.loc['P102503'].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5th</th>\n",
       "      <th>4th</th>\n",
       "      <th>3rd</th>\n",
       "      <th>2nd</th>\n",
       "      <th>1st</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P102503</th>\n",
       "      <td>feat_25</td>\n",
       "      <td>feat_7</td>\n",
       "      <td>feat_3</td>\n",
       "      <td>feat_10</td>\n",
       "      <td>feat_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P102504</th>\n",
       "      <td>feat_4</td>\n",
       "      <td>feat_18</td>\n",
       "      <td>feat_27</td>\n",
       "      <td>feat_9</td>\n",
       "      <td>feat_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P107306</th>\n",
       "      <td>feat_18</td>\n",
       "      <td>feat_16</td>\n",
       "      <td>feat_9</td>\n",
       "      <td>feat_10</td>\n",
       "      <td>feat_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P112400</th>\n",
       "      <td>feat_11</td>\n",
       "      <td>feat_10</td>\n",
       "      <td>feat_27</td>\n",
       "      <td>feat_5</td>\n",
       "      <td>feat_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P113608</th>\n",
       "      <td>feat_10</td>\n",
       "      <td>feat_9</td>\n",
       "      <td>feat_11</td>\n",
       "      <td>feat_27</td>\n",
       "      <td>feat_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                5th      4th      3rd      2nd     1st\n",
       "product_id                                            \n",
       "P102503     feat_25   feat_7   feat_3  feat_10  feat_5\n",
       "P102504      feat_4  feat_18  feat_27   feat_9  feat_5\n",
       "P107306     feat_18  feat_16   feat_9  feat_10  feat_5\n",
       "P112400     feat_11  feat_10  feat_27   feat_5  feat_3\n",
       "P113608     feat_10   feat_9  feat_11  feat_27  feat_5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feature_columns = ['5th', '4th', '3rd', '2nd', '1st']\n",
    "df_top_features_products = pd.DataFrame(data=products_cluster_normalized.argsort(axis = 1)[:, -5:], \n",
    "                                columns=top_feature_columns, index=df_products_cluster_normalized.index)\n",
    "df_top_features_products = df_top_features_products.applymap(lambda index: all_feature_columns[index])\n",
    "df_top_features_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_sentence_product_pos_neg = df_sentence_product_pos_neg.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9cfe52c85ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Sample sentences for top features for each product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_top_features_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_top_features_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_product_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nanawu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4358\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4360\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4361\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4362\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nanawu/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4454\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4455\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4456\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4457\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4458\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-9cfe52c85ca8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Sample sentences for top features for each product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_top_features_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_top_features_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_product_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-9cfe52c85ca8>\u001b[0m in \u001b[0;36mget_product_sentence\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfeat_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_feat_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msample_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mindexes_for_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproduct_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mindexes_for_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_for_prod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msentences_for_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_for_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-9cfe52c85ca8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfeat_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_feat_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msample_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mindexes_for_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproduct_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mindexes_for_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_for_prod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msentences_for_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict_sentence_product_pos_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes_for_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentence_columns = ['5th_sent', '4th_sent', '3rd_sent', '2nd_sent', '1st_sent']\n",
    "def get_product_sentence(row):\n",
    "    product_id = row.name\n",
    "    for top_feat_col in top_feature_columns:\n",
    "        # print(product_id, top_feat_col, row[top_feat_col])\n",
    "        feat_col = row[top_feat_col]       \n",
    "        sample_sentence = ''\n",
    "        indexes_for_prod = [k for k, v in dict_sentence_product_pos_neg['product_id'].items() if v == product_id]\n",
    "        indexes_for_feat = [k for k in indexes_for_prod if dict_sentence_product_pos_neg[feat_col][k] > 0]\n",
    "        sentences_for_feat = [dict_sentence_product_pos_neg['sentence'][k] for k in indexes_for_feat]\n",
    "        if (len(sentences_for_feat) > 0):\n",
    "            sample_sentence = sentences_for_feat[0]\n",
    "        row[top_feat_col + '_sent'] = sample_sentence\n",
    "    return row\n",
    "\n",
    "# Sample sentences for top features for each product\n",
    "df_top_features_products = df_top_features_products.apply(lambda row: get_product_sentence(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_features_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Product Sentence Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_products_cluster_centered = df_sentence_products_clusters - df_sentence_products_clusters.mean()\n",
    "# df_products_cluster_centered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "# Transform X_centered to X_pca via a fit_transform\n",
    "products_cluster_counts_pca = pca.fit_transform(products_cluster_normalized)\n",
    "plt.bar(range(1, 21), pca.explained_variance_ratio_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kmeans_inertia(products_cluster_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cluster_count = 7\n",
    "km = KMeans(n_clusters=product_cluster_count)\n",
    "product_clusters = km.fit_predict(products_cluster_normalized)\n",
    "product_ids = df_sentence_products_clusters.index\n",
    "\n",
    "cluster_to_product_ids = {}\n",
    "for product_cluster_index in range(0, product_cluster_count):\n",
    "    df_product_indexes = product_ids[product_clusters == product_cluster_index]\n",
    "    product_names = df_product.loc[df_product_indexes]['product_url']\n",
    "    cluster_to_product_ids[product_cluster_index] = product_names\n",
    "# P116609', 'P116610'    \n",
    "cluster_to_product_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, verbose=1, perplexity=70).fit_transform(products_cluster_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=product_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_features_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 sentences for \n",
    "# Write to CSV\n",
    "df_product_filtered = df_product.loc[df_sentence_products_clusters.index]\n",
    "df_product_filtered['cluster'] = product_clusters\n",
    "df_product_filtered['tsne_0'] = X_embedded[:, 0]\n",
    "df_product_filtered['tsne_1'] = X_embedded[:, 1]\n",
    "df_product_filtered = pd.concat([df_product_filtered, df_top_features_products], axis=1)\n",
    "df_product_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_product_filtered.to_csv('data/tsne_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(X_embedded[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]], np.int32)\n",
    "normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
